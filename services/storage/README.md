# Storage Layer - Arquitectura HÃ­brida

## VisiÃ³n General

Este componente implementa una **arquitectura de almacenamiento hÃ­brida** que combina Prometheus (hot storage) y Cassandra (cold storage) para optimizar el rendimiento de queries en tiempo real mientras mantiene capacidades de anÃ¡lisis histÃ³rico a largo plazo.

## Arquitectura del Sistema

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                     INGESTA DE TELEMETRÃA                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                             â”‚
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚   Collector     â”‚
                    â”‚  (Dispatcher)   â”‚
                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                             â”‚
                â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                â”‚                         â”‚
        â”Œâ”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”        â”Œâ”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”
        â”‚   HOT PATH     â”‚        â”‚  COLD PATH   â”‚
        â”‚  (Tiempo Real) â”‚        â”‚  (HistÃ³rico) â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜        â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
                â”‚                        â”‚
        â”Œâ”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”        â”Œâ”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚  PROMETHEUS    â”‚        â”‚   CASSANDRA      â”‚
        â”‚                â”‚        â”‚                  â”‚
        â”‚  - RetenciÃ³n:  â”‚        â”‚  - RetenciÃ³n:    â”‚
        â”‚    30 dÃ­as     â”‚        â”‚    1-2 aÃ±os      â”‚
        â”‚  - Queries:    â”‚        â”‚  - Queries:      â”‚
        â”‚    50-200ms    â”‚        â”‚    500-2000ms    â”‚
        â”‚  - Storage:    â”‚        â”‚  - Storage:      â”‚
        â”‚    In-Memory   â”‚        â”‚    Disk-based    â”‚
        â”‚    + SSD       â”‚        â”‚    Distributed   â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜        â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                â”‚                        â”‚
                â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                             â”‚
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚    GRAFANA      â”‚
                    â”‚  (VisualizaciÃ³n)â”‚
                    â”‚                 â”‚
                    â”‚  Query Router:  â”‚
                    â”‚  < 30d â†’ Prom   â”‚
                    â”‚  > 30d â†’ Cass   â”‚
                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ”¥ Hot Path: Prometheus (Tiempo Real)

### PropÃ³sito
Almacenamiento optimizado para **queries ultra-rÃ¡pidas** de datos recientes, diseÃ±ado para dashboards en tiempo real y alertas inmediatas.

### CaracterÃ­sticas

#### Ventajas
- âš¡ **Latencia ultra-baja**: 50-200ms por query
- ğŸ“Š **Optimizado para series temporales**: CompresiÃ³n eficiente
- ğŸ¯ **PromQL nativo**: Lenguaje de queries poderoso
- ğŸ”” **Alerting integrado**: Alertmanager built-in
- ğŸ“ˆ **Agregaciones rÃ¡pidas**: Rate, sum, avg en milisegundos

#### ConfiguraciÃ³n de RetenciÃ³n

```yaml
# prometheus.yml
global:
  scrape_interval: 15s
  evaluation_interval: 15s

# ConfiguraciÃ³n de almacenamiento
storage:
  tsdb:
    path: /prometheus/data
    retention.time: 30d          # Retener solo 30 dÃ­as
    retention.size: 100GB         # LÃ­mite de espacio
    wal-compression: true         # Comprimir WAL

# Recibir datos del Collector
remote_write:
  - url: "http://cassandra-adapter:9201/write"  # TambiÃ©n escribir a Cassandra
    queue_config:
      capacity: 10000
      max_shards: 50
      min_shards: 1
      max_samples_per_send: 5000
      batch_send_deadline: 5s

scrape_configs:
  - job_name: 'otel-collector'
    static_configs:
      - targets: ['collector:8889']
```

#### Casos de Uso
- âœ… Dashboards en tiempo real
- âœ… Alertas crÃ­ticas (< 5 minutos)
- âœ… Troubleshooting activo
- âœ… AnÃ¡lisis de Ãºltimas 24-72 horas
- âœ… Queries ad-hoc frecuentes

#### LÃ­mites
- âŒ No apto para retenciÃ³n > 90 dÃ­as (costo/espacio)
- âŒ Escalabilidad vertical limitada
- âŒ No distribuido (single point of failure)

---

## â„ï¸ Cold Path: Cassandra (HistÃ³rico)

### PropÃ³sito
Almacenamiento distribuido para **anÃ¡lisis histÃ³rico**, compliance, auditorÃ­a y retenciÃ³n a largo plazo con alta disponibilidad.

### CaracterÃ­sticas

#### Ventajas
- ğŸ’¾ **RetenciÃ³n masiva**: 1-2 aÃ±os (o mÃ¡s) sin problema
- ğŸŒ **Distribuido**: RÃ©plicas en mÃºltiples nodos
- ğŸ“ˆ **Escalabilidad horizontal**: Agregar nodos segÃºn necesidad
- ğŸ”’ **Durabilidad**: Sin pÃ©rdida de datos (replicaciÃ³n)
- âš¡ **Write-optimized**: Alto throughput de escrituras

#### Arquitectura del Cluster

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚           Cassandra Ring (Cluster)                  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                      â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”‚
â”‚  â”‚  Node 1  â”‚â”€â”€â”€â–¶â”‚  Node 2  â”‚â”€â”€â”€â–¶â”‚  Node 3  â”‚     â”‚
â”‚  â”‚ (Primary)â”‚    â”‚ (Replica)â”‚    â”‚ (Replica)â”‚     â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â”‚
â”‚       â–²                                   â”‚         â”‚
â”‚       â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜         â”‚
â”‚                  Replication Factor: 3              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

#### Esquema de Base de Datos

```cql
-- Keyspace para telemetrÃ­a
CREATE KEYSPACE IF NOT EXISTS observability 
WITH replication = {
    'class': 'NetworkTopologyStrategy',
    'datacenter1': 3  -- 3 rÃ©plicas
};

-- Tabla para mÃ©tricas (wide-column model)
CREATE TABLE observability.metrics (
    customer_id text,
    node_id text,
    metric_name text,
    timestamp timestamp,
    value double,
    labels map<text, text>,
    PRIMARY KEY ((customer_id, node_id, metric_name), timestamp)
) WITH CLUSTERING ORDER BY (timestamp DESC)
  AND compaction = {
      'class': 'TimeWindowCompactionStrategy',
      'compaction_window_size': 1,
      'compaction_window_unit': 'DAYS'
  }
  AND default_time_to_live = 63072000;  -- 2 aÃ±os en segundos

-- Ãndice secundario para queries por customer
CREATE INDEX IF NOT EXISTS idx_customer 
ON observability.metrics (customer_id);

-- Tabla para trazas (traces)
CREATE TABLE observability.traces (
    trace_id text,
    span_id text,
    timestamp timestamp,
    customer_id text,
    service_name text,
    operation_name text,
    duration_ms bigint,
    status text,
    span_data blob,  -- JSON serializado
    PRIMARY KEY ((customer_id, trace_id), timestamp, span_id)
) WITH CLUSTERING ORDER BY (timestamp DESC, span_id ASC)
  AND default_time_to_live = 63072000;  -- 2 aÃ±os

-- Tabla materializada para queries por servicio
CREATE MATERIALIZED VIEW observability.traces_by_service AS
    SELECT customer_id, service_name, timestamp, trace_id, span_id
    FROM observability.traces
    WHERE customer_id IS NOT NULL 
      AND trace_id IS NOT NULL
      AND service_name IS NOT NULL
      AND timestamp IS NOT NULL
      AND span_id IS NOT NULL
    PRIMARY KEY ((customer_id, service_name), timestamp, trace_id, span_id)
    WITH CLUSTERING ORDER BY (timestamp DESC);
```

#### ConfiguraciÃ³n de Cassandra

```yaml
# cassandra.yaml (principales configuraciones)
cluster_name: 'ObservabilityCluster'

# Memoria
max_heap_size: 16G
heap_newsize: 4G

# Compaction (optimizado para time-series)
compaction_throughput_mb_per_sec: 256

# Escritura
commitlog_sync: periodic
commitlog_sync_period_in_ms: 10000
concurrent_writes: 128

# Lectura
concurrent_reads: 64
read_request_timeout_in_ms: 10000

# TTL automÃ¡tico (2 aÃ±os)
gc_grace_seconds: 864000  # 10 dÃ­as
```

#### Casos de Uso
- âœ… AnÃ¡lisis histÃ³rico (> 30 dÃ­as)
- âœ… Reportes mensuales/anuales
- âœ… Compliance y auditorÃ­a
- âœ… AnÃ¡lisis de tendencias a largo plazo
- âœ… Capacity planning
- âœ… Forensics post-mortem

#### LÃ­mites
- âŒ Latencia mÃ¡s alta (500-2000ms)
- âŒ Queries complejas mÃ¡s lentas
- âŒ Requiere mÃ¡s recursos (RAM, CPU, disco)
- âŒ Complejidad operacional alta

---

## ğŸ”€ Query Router: LÃ³gica de Enrutamiento

### Estrategia de Routing

El routing de queries se maneja en **Grafana** mediante datasources duales y variables de tiempo:

```javascript
// LÃ³gica conceptual en Grafana
function routeQuery(timeRange) {
    const now = Date.now();
    const thirtyDaysAgo = now - (30 * 24 * 60 * 60 * 1000);
    
    if (timeRange.from > thirtyDaysAgo) {
        // Query reciente: usar Prometheus (fast)
        return "prometheus-datasource";
    } else {
        // Query histÃ³rica: usar Cassandra (slower but has data)
        return "cassandra-datasource";
    }
}
```

### ConfiguraciÃ³n de Grafana

```yaml
# grafana/provisioning/datasources/datasources.yml
apiVersion: 1

datasources:
  # Datasource para datos recientes (< 30 dÃ­as)
  - name: Prometheus-Hot
    type: prometheus
    access: proxy
    url: http://prometheus:9090
    isDefault: true
    jsonData:
      timeInterval: "15s"
      queryTimeout: "30s"
    
  # Datasource para datos histÃ³ricos (> 30 dÃ­as)
  - name: Cassandra-Cold
    type: cassandra-datasource
    access: proxy
    url: http://cassandra-adapter:9042
    jsonData:
      keyspace: "observability"
      consistency: "ONE"
      timeout: "30s"
```

### Panel con Routing AutomÃ¡tico

```json
{
  "datasource": {
    "type": "datasource",
    "uid": "-- Mixed --"
  },
  "targets": [
    {
      "datasource": {
        "type": "prometheus",
        "uid": "prometheus-hot"
      },
      "expr": "rate(cpu_usage[5m])",
      "hide": "${__from:date:YYYY-MM-DD} < ${__from:date:YYYY-MM-DD:-30d}"
    },
    {
      "datasource": {
        "type": "cassandra",
        "uid": "cassandra-cold"
      },
      "query": "SELECT metric_name, value FROM metrics WHERE timestamp >= ? AND timestamp <= ?",
      "hide": "${__from:date:YYYY-MM-DD} >= ${__from:date:YYYY-MM-DD:-30d}"
    }
  ]
}
```

---

## ğŸ“Š Comparativa de Rendimiento

| Aspecto | Prometheus (Hot) | Cassandra (Cold) |
|---------|-----------------|------------------|
| **Latencia tÃ­pica** | 50-200 ms | 500-2000 ms |
| **RetenciÃ³n** | 30 dÃ­as | 1-2 aÃ±os (o mÃ¡s) |
| **Throughput escritura** | 100k samples/s | 1M+ samples/s |
| **Throughput lectura** | Alta (in-memory) | Media (disk-based) |
| **Costo por GB/mes** | $$$$ (SSD rÃ¡pido) | $ (HDD/SSD mixto) |
| **Complejidad operacional** | Baja | Alta |
| **Queries soportadas** | PromQL (rico) | CQL (limitado) |
| **Agregaciones** | Ultra rÃ¡pidas | Lentas (pre-calcular) |
| **Downsampling** | Manual/Externo | Integrado (compaction) |
| **ReplicaciÃ³n** | No nativo | SÃ­ (multi-DC) |

---

## ğŸ”„ Flujo de Datos Completo

### 1. Escritura (Ingesta)

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Agente    â”‚ (Genera telemetrÃ­a)
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
       â”‚ OTLP (gRPC/HTTP)
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Collector  â”‚ (Procesa y despacha)
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
       â”‚
       â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
       â”‚                             â”‚
       â–¼                             â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Prometheus  â”‚              â”‚  Cassandra  â”‚
â”‚ (Remote     â”‚              â”‚  (Remote    â”‚
â”‚  Write)     â”‚              â”‚   Write)    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
  Ãšltimos 30d                  Todo (1-2 aÃ±os)
```

**ConfiguraciÃ³n del Collector:**

```yaml
# otel-collector-config.yaml
exporters:
  # Exportar a Prometheus
  prometheus:
    endpoint: "0.0.0.0:8889"
    namespace: "customer_monitoring"
    
  # Exportar a Cassandra (vÃ­a adapter custom)
  otlphttp/cassandra:
    endpoint: "http://cassandra-adapter:8080/v1/traces"
    tls:
      insecure: true

service:
  pipelines:
    metrics:
      receivers: [otlp]
      processors: [batch]
      exporters: [prometheus, otlphttp/cassandra]  # Dual export
    
    traces:
      receivers: [otlp]
      processors: [batch]
      exporters: [otlphttp/cassandra]  # Solo Cassandra para traces
```

### 2. Lectura (Queries)

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Grafana   â”‚ (Usuario hace query)
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
       â”‚
       â”œâ”€ EvalÃºa time range
       â”‚
       â”œâ”€â”€â–¶ < 30 dÃ­as? â”€â”€â–¶ Query a Prometheus (rÃ¡pido)
       â”‚
       â””â”€â”€â–¶ > 30 dÃ­as? â”€â”€â–¶ Query a Cassandra (lento)
```

---

## ğŸ”§ Downsampling y CompactaciÃ³n

### Estrategia de Downsampling

A medida que los datos envejecen, reducir la resoluciÃ³n para ahorrar espacio:

```
Edad de datos     â”‚ ResoluciÃ³n    â”‚ Storage
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
0-7 dÃ­as          â”‚ 15 segundos   â”‚ Prometheus
7-30 dÃ­as         â”‚ 1 minuto      â”‚ Prometheus
30-90 dÃ­as        â”‚ 5 minutos     â”‚ Cassandra
90-365 dÃ­as       â”‚ 15 minutos    â”‚ Cassandra
1-2 aÃ±os          â”‚ 1 hora        â”‚ Cassandra
> 2 aÃ±os          â”‚ Eliminado     â”‚ -
```

**ImplementaciÃ³n con Cassandra TTL:**

```cql
-- Tabla para datos raw (alta resoluciÃ³n)
CREATE TABLE metrics_raw (
    ...
) WITH default_time_to_live = 2592000;  -- 30 dÃ­as

-- Tabla para datos downsampled 5min
CREATE TABLE metrics_5min (
    ...
) WITH default_time_to_live = 7776000;  -- 90 dÃ­as

-- Tabla para datos downsampled 1h
CREATE TABLE metrics_1h (
    ...
) WITH default_time_to_live = 63072000;  -- 2 aÃ±os
```

**Job de Downsampling (Spark/Airflow):**

```python
# Pseudo-cÃ³digo del job diario
def downsample_daily():
    # Agregar datos de 30 dÃ­as atrÃ¡s (ya no en Prometheus)
    query = """
        SELECT customer_id, metric_name, 
               date_trunc('minute', timestamp, 5) as ts_5min,
               avg(value) as avg_value,
               max(value) as max_value,
               min(value) as min_value
        FROM metrics_raw
        WHERE timestamp >= now() - interval '31 days'
          AND timestamp < now() - interval '30 days'
        GROUP BY customer_id, metric_name, ts_5min
    """
    
    # Insertar en tabla downsampled
    results = cassandra.execute(query)
    cassandra.batch_insert('metrics_5min', results)
```

---

## ğŸš€ Deployment

### Docker Compose

```yaml
version: '3.8'

services:
  # Prometheus (Hot Storage)
  prometheus:
    image: prom/prometheus:latest
    container_name: prometheus-hot
    volumes:
      - ./prometheus/prometheus.yml:/etc/prometheus/prometheus.yml
      - prometheus-data:/prometheus
    command:
      - '--config.file=/etc/prometheus/prometheus.yml'
      - '--storage.tsdb.path=/prometheus'
      - '--storage.tsdb.retention.time=30d'
      - '--storage.tsdb.retention.size=100GB'
      - '--web.enable-lifecycle'
    ports:
      - "9090:9090"
    networks:
      - observability

  # Cassandra Node 1 (Cold Storage)
  cassandra-1:
    image: cassandra:4.1
    container_name: cassandra-cold-1
    environment:
      - CASSANDRA_CLUSTER_NAME=ObservabilityCluster
      - CASSANDRA_DC=datacenter1
      - CASSANDRA_RACK=rack1
      - CASSANDRA_ENDPOINT_SNITCH=GossipingPropertyFileSnitch
      - MAX_HEAP_SIZE=16G
      - HEAP_NEWSIZE=4G
    volumes:
      - cassandra-data-1:/var/lib/cassandra
    ports:
      - "9042:9042"
    networks:
      - observability
    healthcheck:
      test: ["CMD-SHELL", "nodetool status"]
      interval: 30s
      timeout: 10s
      retries: 5

  # Cassandra Node 2
  cassandra-2:
    image: cassandra:4.1
    container_name: cassandra-cold-2
    environment:
      - CASSANDRA_CLUSTER_NAME=ObservabilityCluster
      - CASSANDRA_DC=datacenter1
      - CASSANDRA_RACK=rack2
      - CASSANDRA_SEEDS=cassandra-1
    volumes:
      - cassandra-data-2:/var/lib/cassandra
    networks:
      - observability
    depends_on:
      - cassandra-1

  # Cassandra Node 3
  cassandra-3:
    image: cassandra:4.1
    container_name: cassandra-cold-3
    environment:
      - CASSANDRA_CLUSTER_NAME=ObservabilityCluster
      - CASSANDRA_DC=datacenter1
      - CASSANDRA_RACK=rack3
      - CASSANDRA_SEEDS=cassandra-1
    volumes:
      - cassandra-data-3:/var/lib/cassandra
    networks:
      - observability
    depends_on:
      - cassandra-1

  # Cassandra Adapter (Prometheus -> Cassandra bridge)
  cassandra-adapter:
    image: cassandra-prometheus-adapter:latest
    container_name: cassandra-adapter
    environment:
      - CASSANDRA_HOSTS=cassandra-1,cassandra-2,cassandra-3
      - CASSANDRA_KEYSPACE=observability
      - CASSANDRA_CONSISTENCY=QUORUM
    ports:
      - "9201:9201"
    networks:
      - observability
    depends_on:
      - cassandra-1

  # Grafana (Visualization)
  grafana:
    image: grafana/grafana:latest
    container_name: grafana
    volumes:
      - ./grafana/provisioning:/etc/grafana/provisioning
      - grafana-data:/var/lib/grafana
    environment:
      - GF_SECURITY_ADMIN_PASSWORD=admin
      - GF_USERS_ALLOW_SIGN_UP=false
    ports:
      - "3000:3000"
    networks:
      - observability
    depends_on:
      - prometheus
      - cassandra-adapter

volumes:
  prometheus-data:
  cassandra-data-1:
  cassandra-data-2:
  cassandra-data-3:
  grafana-data:

networks:
  observability:
    driver: bridge
```

---

## ğŸ“ˆ Monitoring del Storage Layer

### MÃ©tricas Clave a Monitorear

#### Prometheus
```promql
# Uso de disco
prometheus_tsdb_storage_blocks_bytes

# Tasa de ingesta
rate(prometheus_tsdb_head_samples_appended_total[5m])

# Latencia de queries
prometheus_http_request_duration_seconds{handler="/api/v1/query"}
```

#### Cassandra
```bash
# Via nodetool
nodetool status           # Estado del cluster
nodetool tpstats          # Thread pool stats
nodetool cfstats          # Table statistics
nodetool tablestats       # Disk usage per table

# MÃ©tricas JMX expuestas
org.apache.cassandra.metrics:type=ClientRequest,scope=Read,name=Latency
org.apache.cassandra.metrics:type=Storage,name=Load
```

---

## ğŸ¯ Best Practices

### âœ… DO:
- **Etiquetar correctamente**: Todos los datos con `customer_id`, `node_id`, `environment`
- **Monitoring del monitoring**: Alertas sobre latencia de storage
- **Backups regulares**: Snapshots de Cassandra cada 24h
- **Testing de disaster recovery**: Simular caÃ­das de nodos
- **Capacity planning**: Monitorear crecimiento de datos semanalmente

### âŒ DON'T:
- **No queries pesadas en Prometheus**: Usar recording rules
- **No retenciÃ³n infinita**: Respetar TTLs, limpiar datos antiguos
- **No single point of failure**: MÃ­nimo 3 nodos Cassandra
- **No ignores compaction**: Configurar ventanas de mantenimiento
- **No subestimar recursos**: Cassandra necesita memoria y disco generosos

---

## ğŸ” Troubleshooting

### Problema: Queries lentas en Grafana
```bash
# Verificar quÃ© datasource estÃ¡ siendo usado
# Si es Prometheus y > 30 dÃ­as: BUG en routing
# Si es Cassandra y < 30 dÃ­as: BUG en routing

# Check latencia Prometheus
curl http://prometheus:9090/api/v1/query?query=up

# Check latencia Cassandra
cqlsh -e "SELECT * FROM observability.metrics LIMIT 1;"
```

### Problema: Cassandra nodo caÃ­do
```bash
# Verificar estado del cluster
nodetool status

# Reiniciar nodo
docker restart cassandra-cold-2

# Reparar datos (despuÃ©s de reinicio)
nodetool repair -pr observability
```

### Problema: Prometheus sin espacio
```bash
# Reducir retenciÃ³n temporalmente
# En prometheus.yml: retention.time: 15d

# O expandir disco
docker volume inspect prometheus-data
```

---

## ğŸ“š Referencias

- [Prometheus Documentation](https://prometheus.io/docs/)
- [Cassandra Documentation](https://cassandra.apache.org/doc/)
- [OpenTelemetry Collector](https://opentelemetry.io/docs/collector/)
- [Grafana Provisioning](https://grafana.com/docs/grafana/latest/administration/provisioning/)
- [Time-Series Data on Cassandra](https://www.datastax.com/blog/time-series-data-cassandra)

---

## ğŸ¯ Resumen

Este storage layer hÃ­brido proporciona:
- âš¡ **Rendimiento Ã³ptimo** para queries en tiempo real (Prometheus)
- ğŸ’¾ **RetenciÃ³n masiva** para compliance y anÃ¡lisis histÃ³rico (Cassandra)
- ğŸ”€ **Routing inteligente** segÃºn antigÃ¼edad de datos
- ğŸ“ˆ **Escalabilidad** horizontal y vertical
- ğŸ›¡ï¸ **Alta disponibilidad** mediante replicaciÃ³n

**Trade-off aceptado**: Mayor complejidad operacional a cambio de zero data loss y capacidades enterprise de anÃ¡lisis histÃ³rico.
