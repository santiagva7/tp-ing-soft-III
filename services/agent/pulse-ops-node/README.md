# Pulse Ops Node - Next.js Agent

Agente de monitoreo construido con Next.js 16 y OpenTelemetry para recolectar mÃ©tricas de sistema (CPU, RAM).

**Arquitectura resiliente con persistencia local**: El agente envÃ­a mÃ©tricas a un **OpenTelemetry Collector local** que:
- Exporta a **Collector Central** (cuando estÃ¡ disponible)
- Persiste localmente en **Cassandra Agent Node** (para resiliencia offline)
- Garantiza **no pÃ©rdida de datos** mediante replicaciÃ³n automÃ¡tica

## ğŸ—ï¸ Arquitectura del Agente

### Flujo de datos completo (con resiliencia)

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ AGENT MACHINE                                                       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                      â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    OTLP/gRPC (4317)   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚  Next.js App     â”‚â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€>â”‚ Local Collector  â”‚  â”‚
â”‚  â”‚  (pulse-ops-node)â”‚    localhost:4317      â”‚  (OTel Collector)â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                        â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚   â€¢ CPU metrics                                       â”‚             â”‚
â”‚   â€¢ RAM metrics                              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚   â€¢ Customer labels                          â”‚  Dual Exporters â”‚   â”‚
â”‚                                              â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”˜   â”‚
â”‚                                                   â”‚          â”‚      â”‚
â”‚                                                   â”‚          â”‚      â”‚
â”‚                                      OTLP/gRPC   â”‚          â”‚ HTTP â”‚
â”‚                                      (retry +    â”‚          â”‚ POST â”‚
â”‚                                       queue)     â”‚          â”‚      â”‚
â”‚                                                   â”‚          â–¼      â”‚
â”‚                                                   â”‚    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚                                                   â”‚    â”‚ Cassandraâ”‚ â”‚
â”‚                                                   â”‚    â”‚  Adapter â”‚ â”‚
â”‚                                                   â”‚    â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜ â”‚
â”‚                                                   â”‚          â”‚      â”‚
â”‚                                                   â”‚          â–¼      â”‚
â”‚                                                   â”‚    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚                                                   â”‚    â”‚ Cassandraâ”‚ â”‚
â”‚                                                   â”‚    â”‚  Node    â”‚ â”‚
â”‚                                                   â”‚    â”‚ (Agent)  â”‚ â”‚
â”‚                                                   â”‚    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                                    â”‚
                                                    â”‚ Internet/Network
                                                    â–¼
                              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                              â”‚ CENTRAL INFRASTRUCTURE              â”‚
                              â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
                              â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”              â”‚
                              â”‚  â”‚ Central Collectorâ”‚              â”‚
                              â”‚  â”‚  (port 4317)     â”‚              â”‚
                              â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜              â”‚
                              â”‚           â”‚                         â”‚
                              â”‚           â–¼                         â”‚
                              â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”              â”‚
                              â”‚  â”‚   Prometheus     â”‚              â”‚
                              â”‚  â”‚   (hot storage)  â”‚              â”‚
                              â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜              â”‚
                              â”‚                                     â”‚
                              â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”              â”‚
                              â”‚  â”‚ Cassandra Clusterâ”‚              â”‚
                              â”‚  â”‚ (3 nodes: cold)  â”‚â—„â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚
                              â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜         â”‚    â”‚
                              â”‚                                â”‚    â”‚
                              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”˜
                                                               â”‚
                                        Cassandra Gossip Protocol
                                        (auto-replication)
                                                               â”‚
                              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â”‚
                              â””â”€â”€â–º Agent Cassandra Node (replicates data)
```

### Comportamiento en diferentes escenarios

#### âœ… Escenario 1: Todo conectado (normal)
1. **App Next.js** â†’ mÃ©tricas â†’ **Collector Local** (localhost:4317)
2. **Collector Local** procesa y exporta:
   - â†’ **Collector Central** (vÃ­a OTLP/gRPC con retry queue)
   - â†’ **Cassandra Adapter** â†’ **Cassandra Agent Node** (local)
3. **Cassandra Agent Node** replica datos al **Cassandra Cluster** (automÃ¡tico)
4. **Collector Central** â†’ Prometheus (hot) + Cassandra Cluster (cold)
5. Resultado: Datos en **Prometheus + Cassandra Cluster + Cassandra Agent**

#### ğŸ”Œ Escenario 2: Central offline (sin conexiÃ³n a internet/central)
1. **App Next.js** â†’ mÃ©tricas â†’ **Collector Local** âœ…
2. **Collector Local** intenta exportar a **Collector Central** âŒ (falla)
3. **Collector Local** guarda en **persistent queue** (disco) para retry
4. **Collector Local** â†’ **Cassandra Adapter** â†’ **Cassandra Agent Node** âœ… (local)
5. Resultado: Datos **solo en Cassandra Agent** (persistidos localmente)
6. Cuando central vuelve: **queue retry** envÃ­a datos acumulados al central

#### ğŸ’¾ Escenario 3: Cassandra Agent offline (falla nodo local)
1. **App Next.js** â†’ mÃ©tricas â†’ **Collector Local** âœ…
2. **Collector Local** exporta a **Collector Central** âœ…
3. **Collector Local** intenta â†’ **Cassandra Adapter** âŒ (falla)
4. Resultado: Datos en **Collector Central** â†’ Prometheus + Cassandra Cluster
5. PÃ©rdida: Solo la copia local del agente (pero datos siguen en cluster central)

### Ventajas de esta arquitectura

| Ventaja | DescripciÃ³n |
|---------|-------------|
| **ğŸ›¡ï¸ Resiliencia** | Datos no se pierden si central cae (persistent queue + Cassandra local) |
| **âš¡ Baja latencia** | Escritura local en Cassandra Agent (< 5ms), no espera a central |
| **ğŸ”„ Auto-replicaciÃ³n** | Cassandra se encarga de sincronizar agente â†” cluster automÃ¡ticamente |
| **ğŸ“Š Formato consistente** | Mismo pipeline de procesamiento (local collector = central config) |
| **ğŸ¯ Edge computing** | Cada agente puede operar independientemente |
| **ğŸ“ˆ Escalable** | Agregar agentes = agregar nodos Cassandra al cluster |

### Componentes del agente

1. **Next.js App** (`pulse-ops-node`):
   - Genera mÃ©tricas de sistema (CPU, RAM)
   - EnvÃ­a vÃ­a OpenTelemetry SDK a `localhost:4317`
   
2. **Local Collector** (`otel-collector`):
   - Recibe OTLP/gRPC en puerto 4317
   - Aplica procesamiento (batch, attributes, filters)
   - Exporta dual: central (retry queue) + local (Cassandra)

3. **Cassandra Adapter**:
   - Recibe mÃ©tricas del collector vÃ­a HTTP POST
   - Transforma a schema Cassandra (`pulseops.metrics`)
   - Inserta en Cassandra Agent Node

4. **Cassandra Agent Node**:
   - Nodo Cassandra que se une al cluster principal
   - Almacena datos localmente (bajo volumen)
   - Replica automÃ¡ticamente al cluster central

## ğŸ“‹ Prerequisitos

- Node.js 18+
- Docker + Docker Compose
- **Cassandra Cluster** corriendo (ver `services/storage/cassandra/`)
- **OpenTelemetry Collector Central** corriendo (opcional si quieres modo standalone)

## ğŸš€ Inicio RÃ¡pido

### OpciÃ³n 1: Desarrollo local (sin Docker)

```bash
# Instalar dependencias
npm install

# Configurar variables de entorno
cp .env.local.example .env.local
# Editar .env.local con tus valores

# Desarrollo
npm run dev
```

**Nota**: En modo dev, la app envÃ­a a `localhost:4317`. Necesitas:
- Local Collector corriendo, o
- Cambiar `OTEL_EXPORTER_OTLP_ENDPOINT` para apuntar directamente al central

### OpciÃ³n 2: Stack completo con Docker Compose (recomendado)

```bash
# 1. Levantar Cassandra Cluster (central)
cd ../../storage/cassandra
docker compose up -d

# 2. Levantar Cassandra Agent Node
cd ../../agent/cassandra
docker compose up -d

# 3. Levantar Local Collector + Adapter + App (TODO: crear compose completo)
cd ../pulse-ops-node
docker compose up -d

# Ver logs del agente
docker compose logs -f pulse-ops-node

# Ver logs del collector local
docker compose logs -f otel-collector-local
```

### OpciÃ³n 3: Solo app en Docker (sin collector local)

```bash
# Build the image
docker build -t pulse-ops-node .

# Run pointing directly to central collector
docker run -p 3001:3001 \
  -e OTEL_EXPORTER_OTLP_ENDPOINT=http://host.docker.internal:4317 \
  -e OTEL_SERVICE_NAME=pulse-ops-node \
  -e CUSTOMER_ID=customer-123 \
  pulse-ops-node
```

**âš ï¸ Sin collector local = sin resiliencia offline**

## ğŸ“Š MÃ©tricas Recolectadas

- `system.cpu.percent` - Porcentaje de uso de CPU
- `system.memory.percent` - Porcentaje de uso de RAM

Las mÃ©tricas se exportan cada **5 segundos** al OpenTelemetry Collector vÃ­a OTLP/gRPC.

## ğŸ”§ ConfiguraciÃ³n

### Variables de entorno de la aplicaciÃ³n

Archivo `.env.local` (desarrollo) o variables en Docker Compose (producciÃ³n):

```env
# OpenTelemetry - Apunta al collector LOCAL (no al central)
OTEL_EXPORTER_OTLP_ENDPOINT=http://localhost:4317

# IdentificaciÃ³n del servicio
OTEL_SERVICE_NAME=pulse-ops-node
CUSTOMER_ID=customer-123

# Entorno
NODE_ENV=production
```

### ConfiguraciÃ³n del Local Collector (TODO)

El collector local (`otel-collector-config.yaml`) debe tener:

**Receivers**:
- `otlp`: gRPC en puerto 4317 (recibe de la app)

**Processors** (mismo que central):
- `batch`: Agrupa mÃ©tricas (5000 metrics, 10s timeout)
- `attributes`: Agrega labels (customer_id, node_id)
- `resource`: Detecta hostname, OS, etc.

**Exporters**:
- `otlp/central`: EnvÃ­a al collector central
  - `endpoint`: `http://host.docker.internal:4317` (o IP real)
  - `retry_on_failure`: enabled
  - `sending_queue`: persistent (disk-based)
  - `queue_size`: 5000
- `otlphttp/cassandra-adapter`: EnvÃ­a al adapter local
  - `endpoint`: `http://cassandra-adapter:8080/metrics`
  - `timeout`: 5s

### Cassandra Adapter (TODO)

PequeÃ±o servicio HTTP que recibe mÃ©tricas OTLP y escribe a Cassandra:

```typescript
// POST /metrics
{
  "resourceMetrics": [{
    "resource": { "attributes": [{"key": "customer.id", "value": "customer-123"}] },
    "scopeMetrics": [{
      "metrics": [{
        "name": "system.cpu.percent",
        "gauge": { "dataPoints": [{"timeUnixNano": "...", "asDouble": 45.5}] }
      }]
    }]
  }]
}
```

Transforma a:
```sql
INSERT INTO pulseops.metrics (node_id, metric_name, time_bucket, timestamp, value)
VALUES ('pulse-ops-node', 'system.cpu.percent', '2025-11-04', '2025-11-04 12:34:56', 45.5);
```

## ğŸ§ª Verificar que Funciona

### Logs esperados en la app Next.js

Al ejecutar `npm run dev` o `docker compose up`:

```log
ğŸš€ Inicializando OpenTelemetry...
âœ… OpenTelemetry inicializado correctamente
   ğŸ“¡ Collector: http://localhost:4317
   ğŸ·ï¸  Service: pulse-ops-node
   ğŸ‘¤ Customer: customer-123
ğŸ“Š Registrando mÃ©tricas del sistema...
âœ… MÃ©tricas del sistema registradas (CPU, RAM)
[12:34:56] ğŸ“Š system.cpu.percent: 45.23%
[12:34:56] ğŸ“Š system.memory.percent: 68.91%
```

Cada **5 segundos** verÃ¡s nuevos logs con valores actualizados.

### Verificar collector local recibe mÃ©tricas

```bash
# Ver logs del collector local
docker compose logs -f otel-collector-local

# DeberÃ­as ver:
# 2025-11-04T12:34:56.123Z  info  exporterhelper/queued_retry.go  Exporting
# 2025-11-04T12:34:56.456Z  info  otlp/exporter.go  Sent metrics to central
```

### Verificar datos en Cassandra Agent

```bash
# Conectar al nodo Cassandra del agente
docker exec -it pulseops-agent-cassandra cqlsh

# Query reciente
SELECT * FROM pulseops.metrics 
WHERE node_id='pulse-ops-node' 
  AND metric_name='system.cpu.percent' 
  AND time_bucket='2025-11-04'
LIMIT 10;

# DeberÃ­as ver filas con timestamps recientes
```

### Verificar replicaciÃ³n al cluster central

```bash
# Conectar al nodo central
docker exec -it pulseops-db-1 cqlsh

# Misma query (datos deben estar replicados)
SELECT * FROM pulseops.metrics 
WHERE node_id='pulse-ops-node' 
  AND metric_name='system.cpu.percent' 
  AND time_bucket='2025-11-04'
LIMIT 10;
```

### Probar resiliencia (offline mode)

```bash
# 1. Detener el collector central
cd ../../../../collector
docker compose down

# 2. App sigue enviando al local collector
docker compose -f ../agent/pulse-ops-node/docker-compose.yml logs -f

# 3. Verificar que datos se guardan en Cassandra local
docker exec -it pulseops-agent-cassandra cqlsh -e "
  SELECT COUNT(*) FROM pulseops.metrics 
  WHERE node_id='pulse-ops-node' 
    AND metric_name='system.cpu.percent' 
    AND time_bucket='2025-11-04';
"

# 4. Reiniciar collector central
docker compose up -d

# 5. Ver logs: el collector local enviarÃ¡ datos acumulados (retry queue)
docker compose -f ../agent/pulse-ops-node/docker-compose.yml logs otel-collector-local
# DeberÃ­as ver: "Retrying batch send" y luego "Successfully sent"
```

## ğŸš€ PrÃ³ximos Pasos (ImplementaciÃ³n)

Para completar esta arquitectura, necesitamos crear:

### 1. Local Collector
- [ ] `services/agent/collector/config/otel-collector-config.yaml`
- [ ] `services/agent/collector/docker-compose.yml`
- [ ] Configurar receivers, processors, exporters (dual)

### 2. Cassandra Adapter
- [ ] `services/agent/adapter/src/index.ts` (HTTP server + Cassandra client)
- [ ] `services/agent/adapter/Dockerfile`
- [ ] `services/agent/adapter/package.json`

### 3. Docker Compose Unificado
- [ ] Actualizar `services/agent/pulse-ops-node/docker-compose.yml`
- [ ] Incluir: app + collector + adapter + Cassandra node
- [ ] Configurar networks y dependencias

### 4. Testing
- [ ] Probar flujo completo: app â†’ collector â†’ dual export
- [ ] Probar modo offline y recovery
- [ ] Verificar replicaciÃ³n Cassandra

**Â¿Quieres que implemente estos componentes ahora?** ğŸš€

Puedo crear:
- Collector config con retry queue + dual exporters
- Adapter HTTP â†’ Cassandra (Node.js con cassandra-driver)
- Docker compose completo con todos los servicios
- Scripts de testing para verificar resiliencia

---

## ğŸ“Š MÃ©tricas Recolectadas

- `system.cpu.percent` - Porcentaje de uso de CPU (ObservableGauge con delta)
- `system.memory.percent` - Porcentaje de uso de RAM (ObservableGauge)

Las mÃ©tricas se exportan cada **5 segundos** al Local Collector vÃ­a OTLP/gRPC.

**Labels automÃ¡ticos**:
- `customer.id`: ID del cliente (multi-tenant)
- `service.name`: Nombre del servicio (`pulse-ops-node`)
- `host.name`: Hostname del agente
- `node.id`: ID Ãºnico del nodo generado automÃ¡ticamente

## ğŸ³ Docker Deployment (ProducciÃ³n)

La imagen usa **standalone output** con multi-stage builds:
- TamaÃ±o final: **~110MB** (vs ~1GB sin standalone)
- Base: `node:20-alpine`
- User: non-root `nodejs` (seguridad)

Puerto expuesto: **3001**

La aplicaciÃ³n corre en <http://localhost:3001>.

