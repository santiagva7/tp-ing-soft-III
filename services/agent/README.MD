# ðŸ—ï¸ Arquitectura del Agente PulseOps

## ðŸ“Š Flujo de Datos Actualizado

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                       AGENT NODE (Edge Device)                        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                        â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                                             â”‚
â”‚  â”‚  pulse-ops-node     â”‚  MÃ©tricas del sistema:                      â”‚
â”‚  â”‚  (Next.js 16)       â”‚  â€¢ system.cpu.percent                       â”‚
â”‚  â”‚                     â”‚  â€¢ system.memory.percent                    â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                                             â”‚
â”‚             â”‚                                                          â”‚
â”‚             â”‚ OTLP/gRPC                                               â”‚
â”‚             â”‚ localhost:4317                                          â”‚
â”‚             â–¼                                                          â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                                             â”‚
â”‚  â”‚  collector-agent    â”‚  Procesa:                                   â”‚
â”‚  â”‚  (OTel Collector)   â”‚  â€¢ Batch                                    â”‚
â”‚  â”‚                     â”‚  â€¢ Attributes (collector.name, node.id)     â”‚
â”‚  â”‚                     â”‚  â€¢ Resource detection                       â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                                             â”‚
â”‚             â”‚                                                          â”‚
â”‚             â”‚ OTLP/HTTP                                               â”‚
â”‚             â”‚ cassandra-adapter:8080                                  â”‚
â”‚             â–¼                                                          â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                                             â”‚
â”‚  â”‚  cassandra-adapter  â”‚  Convierte OTLP â†’ CQL:                      â”‚
â”‚  â”‚  (Node.js HTTP)     â”‚  â€¢ Parsea resourceMetrics                   â”‚
â”‚  â”‚                     â”‚  â€¢ Extrae node_id, customer_id              â”‚
â”‚  â”‚                     â”‚  â€¢ INSERT batch a Cassandra                 â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                                             â”‚
â”‚             â”‚                                                          â”‚
â”‚             â”‚ CQL Protocol                                            â”‚
â”‚             â”‚ cassandra-agent:9042                                    â”‚
â”‚             â–¼                                                          â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                                             â”‚
â”‚  â”‚  cassandra-agent    â”‚  Cluster member:                            â”‚
â”‚  â”‚  (Cassandra 5.0)    â”‚  â€¢ Cluster: PulseOpsCluster                 â”‚
â”‚  â”‚                     â”‚  â€¢ DC: dc1, Rack: rack4                     â”‚
â”‚  â”‚                     â”‚  â€¢ Seeds: cassandra-1,2,3                   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                                             â”‚
â”‚             â”‚                                                          â”‚
â”‚             â”‚ Gossip Protocol                                         â”‚
â”‚             â”‚ (Auto-replication)                                      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
              â”‚
              â”‚ Cluster Sync
              â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    CENTRAL INFRASTRUCTURE                             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                        â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚                  Cassandra Cluster (dc1)                      â”‚   â”‚
â”‚  â”‚                                                                â”‚   â”‚
â”‚  â”‚    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”        â”‚   â”‚
â”‚  â”‚    â”‚cassandra-1 â”‚    â”‚cassandra-2 â”‚    â”‚cassandra-3 â”‚        â”‚   â”‚
â”‚  â”‚    â”‚  (rack1)   â”‚â—„â”€â”€â–ºâ”‚  (rack2)   â”‚â—„â”€â”€â–ºâ”‚  (rack3)   â”‚        â”‚   â”‚
â”‚  â”‚    â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜        â”‚   â”‚
â”‚  â”‚          â”‚                   â”‚                  â”‚              â”‚   â”‚
â”‚  â”‚          â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜              â”‚   â”‚
â”‚  â”‚                              â”‚                                 â”‚   â”‚
â”‚  â”‚                              â”‚ Gossip + Replication            â”‚   â”‚
â”‚  â”‚                              â”‚                                 â”‚   â”‚
â”‚  â”‚                       â”Œâ”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”                          â”‚   â”‚
â”‚  â”‚                       â”‚cassandra-   â”‚â—„â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”¤
â”‚  â”‚                       â”‚   agent     â”‚  Cluster Member          â”‚   â”‚
â”‚  â”‚                       â”‚  (rack4)    â”‚                          â”‚   â”‚
â”‚  â”‚                       â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                          â”‚   â”‚
â”‚  â”‚                                                                 â”‚   â”‚
â”‚  â”‚  Keyspace: pulseops                                            â”‚   â”‚
â”‚  â”‚  Replication: NetworkTopologyStrategy, RF=3                    â”‚   â”‚
â”‚  â”‚  Datos replicados automÃ¡ticamente a 4 nodos                    â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                                                                        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ðŸš€ Componentes

### 1. pulse-ops-node (Next.js 16)
- **FunciÃ³n**: AplicaciÃ³n web que genera mÃ©tricas del sistema
- **TecnologÃ­a**: Next.js 16 + OpenTelemetry SDK
- **MÃ©tricas**:
  - `system.cpu.percent`: Porcentaje de CPU usado
  - `system.memory.percent`: Porcentaje de RAM usado
- **Export**: OTLP/gRPC a `localhost:4317`
- **Frecuencia**: Cada 5 segundos
- **âš ï¸ Cambio importante**: Ya NO escribe directamente a Cassandra

### 2. collector-agent (OpenTelemetry Collector)
- **FunciÃ³n**: Recibe y procesa mÃ©tricas OTLP
- **TecnologÃ­a**: otel/opentelemetry-collector-contrib
- **Processors**:
  - `memory_limiter`: Limita uso de memoria (256MB)
  - `resource`: Detecta hostname, OS, etc.
  - `attributes`: Agrega `collector.name`, `collector.type`
  - `batch`: Agrupa mÃ©tricas (timeout 10s)
- **Export**: OTLP/HTTP a `cassandra-adapter:8080`

### 3. cassandra-adapter (Node.js HTTP Server)
- **FunciÃ³n**: Convierte OTLP â†’ CQL
- **TecnologÃ­a**: Express + cassandra-driver
- **Endpoint**: POST `/v1/metrics`
- **Proceso**:
  1. Recibe `resourceMetrics` OTLP
  2. Extrae `node_id`, `customer_id`, mÃ©tricas
  3. Convierte timestamps (nano â†’ Date)
  4. Genera `time_bucket` (YYYY-MM-DD)
  5. INSERT batch a Cassandra
- **Retry**: Configurado en el collector (retry_on_failure)

### 4. cassandra-agent (Cassandra Node)
- **FunciÃ³n**: Nodo del cluster Cassandra
- **TecnologÃ­a**: Cassandra 5.0
- **ConfiguraciÃ³n**:
  - Cluster: `PulseOpsCluster`
  - Datacenter: `dc1`, Rack: `rack4`
  - Seeds: `cassandra-1`, `cassandra-2`, `cassandra-3`
  - Snitch: `GossipingPropertyFileSnitch`
- **ReplicaciÃ³n**: Miembro completo del cluster (recibe replicaciones automÃ¡ticas)

## ðŸ“‹ Schema de Cassandra

```sql
CREATE KEYSPACE pulseops
WITH replication = {'class': 'NetworkTopologyStrategy', 'dc1': 3};

CREATE TABLE pulseops.metrics (
  node_id text,
  metric_name text,
  time_bucket text,
  timestamp timestamp,
  value double,
  customer_id text,
  PRIMARY KEY ((node_id, metric_name, time_bucket), timestamp)
) WITH CLUSTERING ORDER BY (timestamp DESC)
  AND default_time_to_live = 2592000;  -- 30 dÃ­as TTL
```

**Partition Key**: `(node_id, metric_name, time_bucket)`
- Distribuye datos por nodo + mÃ©trica + dÃ­a
- Permite queries eficientes por nodo/mÃ©trica

**Clustering Key**: `timestamp DESC`
- Ordena mÃ©tricas de mÃ¡s reciente a mÃ¡s antigua
- Ideal para time-series

## ðŸ”§ Despliegue

### Prerequisitos
1. Docker y Docker Compose instalados
2. Cluster Cassandra central levantado (cassandra-1,2,3)

### Orden de inicio

1. **Cluster Cassandra Central** (si no estÃ¡ levantado):
```powershell
cd services/storage/cassandra
docker-compose up -d
# Esperar init: docker logs -f pulseops-db-init
```

2. **Agente (Cassandra + Collector + Adapter)**:
```powershell
cd services/agent/collector
docker-compose up -d
# Esto levanta: cassandra-agent, cassandra-adapter, collector-agent
```

3. **AplicaciÃ³n Next.js**:
```powershell
cd services/agent/pulse-ops-node
npm install  # Remover cassandra-driver del lockfile
npm run dev
```

### Verificar funcionamiento

1. **Logs del collector**:
```powershell
docker logs -f pulseops-collector-agent
```

2. **Logs del adapter**:
```powershell
docker logs -f pulseops-cassandra-adapter
```

3. **Estado del cluster**:
```powershell
docker exec pulseops-agent-cassandra nodetool status
# Debe mostrar 4 nodos (cassandra-1,2,3 + agent)
```

4. **Consultar mÃ©tricas**:
```powershell
docker exec -it pulseops-agent-cassandra cqlsh
```
```sql
SELECT * FROM pulseops.metrics 
WHERE node_id = 'DESKTOP-XXX' 
AND metric_name = 'system.cpu.percent' 
AND time_bucket = '2025-11-04' 
LIMIT 10;
```

## ðŸŽ¯ Ventajas de esta arquitectura

| Ventaja | DescripciÃ³n |
|---------|-------------|
| **ðŸ”„ SeparaciÃ³n de responsabilidades** | App solo genera mÃ©tricas, collector procesa, adapter persiste |
| **ðŸ“Š Sin acoplamiento** | App Next.js NO conoce Cassandra (solo OTLP) |
| **ðŸ›¡ï¸ Alta disponibilidad** | RF=3 + 1 agente = 4 nodos con datos |
| **âš¡ ReplicaciÃ³n automÃ¡tica** | Gossip Protocol sincroniza todos los nodos |
| **ðŸ”§ Extensible** | Agregar nuevos exporters sin modificar la app |
| **ðŸ“ˆ Escalable** | Agregar mÃ¡s agentes = agregar nodos al cluster |
| **ðŸ› Debugging** | Cada componente tiene logs independientes |

## ðŸš¨ Cambios importantes

### âœ… Removido de pulse-ops-node:
- âŒ Cliente de Cassandra (`lib/cassandra.ts`)
- âŒ Escritura directa a Cassandra (`saveToCassandra()`)
- âŒ Dependencia `cassandra-driver`
- âœ… Solo mantiene OpenTelemetry SDK

### âœ… Agregado:
- âœ… `cassandra-adapter` (nuevo servicio Node.js)
- âœ… `collector-agent` (renombrado de `otel-collector`)
- âœ… Campo `customer_id` en tabla metrics

### âš ï¸ Antes de levantar:
```powershell
# Limpiar node_modules y reinstalar
cd services/agent/pulse-ops-node
Remove-Item -Recurse -Force node_modules
npm install
```

## ðŸ“š Variables de entorno

### pulse-ops-node (.env.local)
```env
OTEL_EXPORTER_OTLP_ENDPOINT=http://localhost:4317
OTEL_SERVICE_NAME=pulse-ops-node
CUSTOMER_ID=customer-123
NODE_ENV=production
```

### cassandra-adapter
```env
CASSANDRA_HOST=cassandra-agent
CASSANDRA_PORT=9042
CASSANDRA_DC=dc1
PORT=8080
```

## ðŸ” Troubleshooting

### Problema: Adapter no conecta a Cassandra
```powershell
# Verificar que cassandra-agent estÃ© en el mismo network
docker network inspect cassandra_cassandra-net
```

### Problema: MÃ©tricas no llegan
1. Verificar logs del collector: `docker logs pulseops-collector-agent`
2. Verificar health del adapter: `curl http://localhost:8080/health`
3. Verificar connectivity: `docker exec pulseops-collector-agent ping cassandra-adapter`

### Problema: Cluster no sincroniza
```powershell
# Verificar seeds en cassandra-agent
docker exec pulseops-agent-cassandra nodetool describecluster
```

---

**VersiÃ³n**: 2.0.0  
**Ãšltima actualizaciÃ³n**: Noviembre 4, 2025  
**Stack**: Next.js 16 + OpenTelemetry + Cassandra 5.0

---

## 1. Funcionamiento del Agente

El agente es una **aplicaciÃ³n escrita en Go que implementa el SDK de OpenTelemetry**. Su funciÃ³n principal es **generar y exportar telemetrÃ­a (trazas, mÃ©tricas y logs) en tiempo real** directamente al Collector.

### Arquitectura: Enfoque de OpenTelemetry

OpenTelemetry utiliza un modelo de **observabilidad distribuida** con los siguientes componentes:

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   AplicaciÃ³n Go         â”‚
â”‚   (Agent con SDK)       â”‚
â”‚                         â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚ OpenTelemetry    â”‚   â”‚
â”‚  â”‚ SDK              â”‚   â”‚â”€â”€â”€â”
â”‚  â”‚ - Tracer         â”‚   â”‚   â”‚ Genera telemetrÃ­a
â”‚  â”‚ - Meter          â”‚   â”‚   â”‚ internamente
â”‚  â”‚ - Logger         â”‚   â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚â—„â”€â”€â”˜
â”‚           â”‚             â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚ OTLP Exporter    â”‚   â”‚â”€â”€â”€â”
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚   â”‚ EnvÃ­a datos via OTLP
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚ (cliente, no servidor)
            â”‚                 â”‚
            â”‚ ConexiÃ³n        â”‚
            â”‚ saliente        â”‚
            â–¼                 â–¼
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚   OpenTelemetry Collector   â”‚
    â”‚   (Recibe en 4317/4318)     â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Â¿CÃ³mo logra exportar mÃ©tricas en tiempo real?

El agente implementa el siguiente flujo:

1. **InstrumentaciÃ³n del CÃ³digo**: La aplicaciÃ³n Go utiliza el SDK de OpenTelemetry para instrumentar su cÃ³digo:
   ```go
   import (
       "go.opentelemetry.io/otel"
       "go.opentelemetry.io/otel/exporters/otlp/otlptrace/otlptracegrpc"
       "go.opentelemetry.io/otel/sdk/trace"
   )
   
   // El agente NO expone puertos, sino que se conecta al Collector
   ```

2. **GeneraciÃ³n de TelemetrÃ­a**: El SDK captura automÃ¡ticamente:
   - **Trazas (Traces)**: Seguimiento de solicitudes a travÃ©s de servicios
   - **MÃ©tricas (Metrics)**: Contadores, gauges, histogramas de rendimiento
   - **Logs**: Eventos y mensajes de la aplicaciÃ³n

3. **ExportaciÃ³n en Tiempo Real**: El OTLP Exporter del SDK **se conecta al Collector** (actÃºa como cliente):
   - Se conecta al **Collector en `collector:4317`** (gRPC) o `collector:4318` (HTTP)
   - **NO expone estos puertos**, sino que los consume como cliente
   - EnvÃ­a los datos en formato OTLP de forma continua

4. **Buffer Interno**: El SDK mantiene un buffer en memoria que:
   - Agrupa datos en lotes (batching) para eficiencia
   - Reintenta envÃ­os fallidos
   - **Puede perder datos** si el buffer se llena y el Collector no estÃ¡ disponible

### Ventajas del Enfoque SDK

- **Contexto Rico**: Captura informaciÃ³n detallada desde dentro de la aplicaciÃ³n
- **Bajo Overhead**: El SDK es ligero y optimizado para producciÃ³n
- **PropagaciÃ³n de Contexto**: Mantiene trace context entre servicios distribuidos
- **Vendor Neutral**: Los datos pueden enviarse a cualquier backend compatible con OTLP

## 2. Persistencia de Trazas Perdidas en Cassandra

### Problema: PÃ©rdida de Trazas por Buffer Lleno del SDK

Cuando el **buffer interno del SDK de Go** se llena (debido a alta carga o el Collector no disponible), las trazas nuevas se pierden porque:

- El SDK tiene memoria limitada para no afectar la aplicaciÃ³n principal
- Si el Collector estÃ¡ caÃ­do o lento, el buffer se satura
- El SDK descarta trazas para no consumir toda la RAM

### SoluciÃ³n: Exportador Dual con Fallback a Cassandra

Para evitar pÃ©rdida de datos, la aplicaciÃ³n Go debe configurar **mÃºltiples exportadores** en el SDK:

```go
// ConfiguraciÃ³n del SDK con doble exportaciÃ³n
func initTracer() (*trace.TracerProvider, error) {
    // Exportador principal al Collector (OTLP)
    otlpExporter, err := otlptracegrpc.New(
        context.Background(),
        otlptracegrpc.WithEndpoint("collector:4317"),
        otlptracegrpc.WithInsecure(),
    )
    
    // Exportador de respaldo a Cassandra
    cassandraExporter := NewCassandraExporter(&CassandraConfig{
        Hosts:    []string{"cassandra:9042"},
        Keyspace: "otel_traces",
    })
    
    // SpanProcessor con doble exportaciÃ³n
    tp := trace.NewTracerProvider(
        trace.WithBatcher(otlpExporter,
            trace.WithMaxQueueSize(2048),
            trace.WithMaxExportBatchSize(512),
        ),
        // Fallback a Cassandra cuando OTLP falla
        trace.WithSyncer(cassandraExporter),
    )
    
    return tp, nil
}
```

### Estrategias de ImplementaciÃ³n

#### OpciÃ³n 1: Exportador Personalizado a Cassandra (Recomendado)

Implementar un `SpanExporter` custom en Go que escriba directamente a Cassandra:

```go
type CassandraExporter struct {
    session *gocql.Session
}

func (e *CassandraExporter) ExportSpans(ctx context.Context, spans []trace.ReadOnlySpan) error {
    for _, span := range spans {
        query := `INSERT INTO traces_overflow 
                  (trace_id, span_id, timestamp, service_name, operation_name, trace_data)
                  VALUES (?, ?, ?, ?, ?, ?)`
        
        err := e.session.Query(query,
            span.SpanContext().TraceID().String(),
            span.SpanContext().SpanID().String(),
            span.StartTime(),
            span.Resource().Attributes()["service.name"],
            span.Name(),
            marshalSpan(span),
        ).WithContext(ctx).Exec()
        
        if err != nil {
            return err
        }
    }
    return nil
}
```

#### OpciÃ³n 2: Circuit Breaker con Cola Persistente

Usar un patrÃ³n de Circuit Breaker que escriba a Cassandra cuando el Collector falla:

```go
func (a *Agent) exportWithFallback(spans []trace.ReadOnlySpan) error {
    // Intentar enviar al Collector primero
    err := a.otlpExporter.ExportSpans(context.Background(), spans)
    
    if err != nil {
        // Si falla, persistir en Cassandra
        log.Warn("Collector unavailable, falling back to Cassandra")
        return a.cassandraExporter.ExportSpans(context.Background(), spans)
    }
    
    return nil
}
```

### ImplementaciÃ³n Recomendada

1. **Esquema en Cassandra**:
   ```cql
   CREATE KEYSPACE IF NOT EXISTS otel_traces 
   WITH replication = {'class': 'SimpleStrategy', 'replication_factor': 3};
   
   CREATE TABLE otel_traces.traces_overflow (
       trace_id text,
       span_id text,
       timestamp timestamp,
       service_name text,
       operation_name text,
       trace_data blob,
       PRIMARY KEY (trace_id, span_id)
   );
   ```

2. **PolÃ­tica de RetenciÃ³n**: Configurar TTL (Time To Live) en Cassandra para eliminar automÃ¡ticamente trazas antiguas:
   ```cql
   ALTER TABLE otel_traces.traces_overflow 
   WITH default_time_to_live = 604800;  -- 7 dÃ­as
   ```

3. **RecuperaciÃ³n de Trazas**: Implementar un proceso batch que periÃ³dicamente lea las trazas de Cassandra y las reenvÃ­e al Collector cuando estÃ© disponible.

### Beneficios

- âœ… **Sin pÃ©rdida de datos**: Todas las trazas se preservan incluso bajo alta carga
- âœ… **Alta disponibilidad**: Cassandra proporciona replicaciÃ³n y tolerancia a fallos
- âœ… **Escalabilidad**: Cassandra puede manejar grandes volÃºmenes de escrituras
- âœ… **AnÃ¡lisis posterior**: Las trazas persistidas pueden analizarse posteriormente

---

## ðŸš€ Deployment

### Prerrequisitos

- Docker & Docker Compose (recomendado)
- O Go 1.21+ para compilaciÃ³n nativa
- Acceso de red al Collector central (puerto 4317/4318)

### OpciÃ³n 1: Docker Compose (Recomendado)

```yaml
# docker-compose.yaml
version: '3.8'

services:
  otel-agent:
    image: tu-empresa/otel-agent:latest
    container_name: otel-agent
    environment:
      # ConfiguraciÃ³n del Collector central
      - OTEL_EXPORTER_OTLP_ENDPOINT=http://collector.tuempresa.com:4317
      - OTEL_EXPORTER_OTLP_INSECURE=true
      
      # IdentificaciÃ³n del cliente y nodo
      - CUSTOMER_ID=cliente-a
      - CUSTOMER_NAME=Empresa XYZ
      - NODE_ID=prod-web-01
      - NODE_REGION=us-east-1
      - ENVIRONMENT=production
      
      # ConfiguraciÃ³n del agente
      - HEALTH_CHECK_PORT=8080
      - METRICS_INTERVAL=15s
    ports:
      - "8080:8080"  # Health check endpoint
    networks:
      - monitoring
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "wget", "--spider", "-q", "http://localhost:8080/health"]
      interval: 30s
      timeout: 5s
      retries: 3
    # Recursos limitados (bajo overhead)
    deploy:
      resources:
        limits:
          cpus: '0.5'
          memory: 256M
        reservations:
          cpus: '0.1'
          memory: 64M

networks:
  monitoring:
    driver: bridge
```

**Comandos:**

```bash
# Levantar el agente
docker-compose up -d

# Ver logs
docker logs -f otel-agent

# Verificar health
curl http://localhost:8080/health

# Ver mÃ©tricas
curl http://localhost:8080/metrics
```

### OpciÃ³n 2: Binario Nativo

```bash
# Compilar
cd services/agent
go build -o otel-agent main.go

# Ejecutar
./otel-agent \
  --collector-endpoint=collector.tuempresa.com:4317 \
  --customer-id=cliente-a \
  --node-id=prod-web-01 \
  --health-port=8080
```

### OpciÃ³n 3: Kubernetes DaemonSet

```yaml
apiVersion: apps/v1
kind: DaemonSet
metadata:
  name: otel-agent
  namespace: monitoring
spec:
  selector:
    matchLabels:
      app: otel-agent
  template:
    metadata:
      labels:
        app: otel-agent
    spec:
      containers:
      - name: otel-agent
        image: tu-empresa/otel-agent:latest
        env:
        - name: OTEL_EXPORTER_OTLP_ENDPOINT
          value: "http://collector.observability.svc.cluster.local:4317"
        - name: CUSTOMER_ID
          valueFrom:
            fieldRef:
              fieldPath: metadata.namespace
        - name: NODE_ID
          valueFrom:
            fieldRef:
              fieldPath: spec.nodeName
        ports:
        - containerPort: 8080
          name: health
        resources:
          limits:
            memory: "256Mi"
            cpu: "500m"
          requests:
            memory: "64Mi"
            cpu: "100m"
        livenessProbe:
          httpGet:
            path: /health/live
            port: 8080
          initialDelaySeconds: 10
          periodSeconds: 30
        readinessProbe:
          httpGet:
            path: /health/ready
            port: 8080
          initialDelaySeconds: 5
          periodSeconds: 10
```

---

## ðŸ¥ Health Check Endpoint

El agente expone un endpoint `/health` que proporciona informaciÃ³n detallada sobre su estado.

### Endpoints Disponibles

#### GET `/health` - Health Check General

```bash
curl http://localhost:8080/health
```

**Respuesta cuando estÃ¡ sano:**

```json
{
  "status": "healthy",
  "timestamp": "2025-10-31T10:30:00Z",
  "uptime_seconds": 259200,
  "version": "1.0.0",
  "checks": {
    "application": {
      "status": "healthy",
      "message": "Agent running normally"
    },
    "collector_connectivity": {
      "status": "healthy",
      "endpoint": "collector.tuempresa.com:4317",
      "last_successful_send": "2025-10-31T10:29:45Z",
      "latency_ms": 12
    },
    "buffer": {
      "status": "healthy",
      "current_size": 512,
      "max_size": 2048,
      "usage_percent": 25,
      "dropped_spans": 0
    },
    "system_resources": {
      "status": "healthy",
      "cpu_percent": 5.2,
      "memory_mb": 87.3,
      "memory_percent": 8.5
    }
  }
}
```

**Respuesta cuando estÃ¡ degradado:**

```json
{
  "status": "degraded",
  "timestamp": "2025-10-31T10:30:00Z",
  "uptime_seconds": 259200,
  "version": "1.0.0",
  "checks": {
    "application": {
      "status": "healthy",
      "message": "Agent running normally"
    },
    "collector_connectivity": {
      "status": "unhealthy",
      "endpoint": "collector.tuempresa.com:4317",
      "last_successful_send": "2025-10-31T10:15:00Z",
      "error": "connection timeout",
      "retry_attempts": 5
    },
    "buffer": {
      "status": "warning",
      "current_size": 1536,
      "max_size": 2048,
      "usage_percent": 75,
      "dropped_spans": 12
    },
    "system_resources": {
      "status": "healthy",
      "cpu_percent": 6.8,
      "memory_mb": 95.1,
      "memory_percent": 9.3
    }
  }
}
```

#### GET `/health/live` - Liveness Probe

```bash
curl http://localhost:8080/health/live
```

Responde 200 si el proceso estÃ¡ vivo, 503 si no.

#### GET `/health/ready` - Readiness Probe

```bash
curl http://localhost:8080/health/ready
```

Responde 200 si estÃ¡ listo para recibir trÃ¡fico, 503 si no.

#### GET `/metrics` - MÃ©tricas Prometheus

```bash
curl http://localhost:8080/metrics
```

Expone mÃ©tricas en formato Prometheus para scraping directo.

---

## ðŸ“Š MÃ©tricas Exportadas

### MÃ©tricas del Sistema

```promql
# CPU usage
system_cpu_usage{customer_id="cliente-a", node_id="prod-web-01"}

# Memoria usage
system_memory_usage_bytes{customer_id="cliente-a", node_id="prod-web-01"}

# Disco usage
system_disk_usage_bytes{customer_id="cliente-a", node_id="prod-web-01", mount_point="/"}

# Network I/O
system_network_io_bytes{customer_id="cliente-a", node_id="prod-web-01", direction="tx|rx"}
```

### MÃ©tricas del Agente

```promql
# Estado del buffer
agent_buffer_size{customer_id="cliente-a", node_id="prod-web-01"}
agent_buffer_usage_percent{customer_id="cliente-a", node_id="prod-web-01"}

# Conectividad al Collector
agent_collector_reachable{customer_id="cliente-a", node_id="prod-web-01"}
agent_collector_latency_ms{customer_id="cliente-a", node_id="prod-web-01"}

# Throughput
agent_spans_sent_total{customer_id="cliente-a", node_id="prod-web-01"}
agent_spans_dropped_total{customer_id="cliente-a", node_id="prod-web-01"}
```

---

## ðŸ”§ ConfiguraciÃ³n Avanzada

### Variables de Entorno

| Variable | DescripciÃ³n | Default | Ejemplo |
|----------|-------------|---------|---------|
| `OTEL_EXPORTER_OTLP_ENDPOINT` | URL del Collector | - | `http://collector:4317` |
| `OTEL_EXPORTER_OTLP_INSECURE` | Deshabilitar TLS | `false` | `true` |
| `CUSTOMER_ID` | ID Ãºnico del cliente | - | `cliente-a` |
| `CUSTOMER_NAME` | Nombre del cliente | - | `Empresa XYZ` |
| `NODE_ID` | ID Ãºnico del nodo | `hostname` | `prod-web-01` |
| `NODE_REGION` | RegiÃ³n del nodo | - | `us-east-1` |
| `ENVIRONMENT` | Ambiente | `production` | `staging` |
| `HEALTH_CHECK_PORT` | Puerto health check | `8080` | `8080` |
| `METRICS_INTERVAL` | Intervalo de mÃ©tricas | `15s` | `30s` |
| `BUFFER_MAX_SIZE` | TamaÃ±o mÃ¡ximo buffer | `2048` | `4096` |
| `LOG_LEVEL` | Nivel de logs | `info` | `debug` |

### Archivo de ConfiguraciÃ³n

```yaml
# agent-config.yaml
collector:
  endpoint: "collector.tuempresa.com:4317"
  insecure: true
  timeout: 10s
  retry:
    enabled: true
    initial_interval: 1s
    max_interval: 30s
    max_elapsed_time: 5m

customer:
  id: "cliente-a"
  name: "Empresa XYZ"

node:
  id: "prod-web-01"
  region: "us-east-1"
  environment: "production"

telemetry:
  metrics:
    interval: 15s
    enabled: true
  traces:
    enabled: true
    sample_rate: 1.0
  logs:
    enabled: true
    level: "info"

buffer:
  max_size: 2048
  batch_size: 512
  flush_interval: 5s

health_check:
  port: 8080
  path: "/health"
```

---

## ðŸ” Troubleshooting

### Problema: Agente no puede conectar al Collector

```bash
# 1. Verificar logs
docker logs otel-agent | grep -i error

# 2. Test conectividad de red
telnet collector.tuempresa.com 4317

# 3. Verificar DNS
nslookup collector.tuempresa.com

# 4. Ver health check
curl http://localhost:8080/health | jq '.checks.collector_connectivity'

# 5. Verificar firewall
# Asegurar que puerto 4317 (gRPC) estÃ© abierto
```

### Problema: Buffer saturado

```bash
# 1. Ver estado del buffer
curl http://localhost:8080/health | jq '.checks.buffer'

# 2. Aumentar tamaÃ±o del buffer
# Editar docker-compose.yaml:
# - BUFFER_MAX_SIZE=4096

# 3. Reducir intervalo de mÃ©tricas
# - METRICS_INTERVAL=30s

# 4. Reiniciar agente
docker restart otel-agent
```

### Problema: Alto uso de memoria

```bash
# 1. Ver uso actual
docker stats otel-agent

# 2. Reducir buffer size
# - BUFFER_MAX_SIZE=1024

# 3. Deshabilitar traces si no son necesarias
# - TRACES_ENABLED=false

# 4. Limitar memoria en Docker
# deploy:
#   resources:
#     limits:
#       memory: 128M
```

### Problema: Health check falla

```bash
# 1. Verificar que el puerto estÃ© abierto
netstat -tulpn | grep 8080

# 2. Test directo
curl -v http://localhost:8080/health

# 3. Ver logs del agente
docker logs otel-agent | tail -50

# 4. Verificar si el proceso estÃ¡ vivo
docker exec otel-agent ps aux | grep otel-agent
```

---

## ðŸ”” Monitoreo del Agente

### Alertas Recomendadas en Prometheus

```yaml
groups:
  - name: agent_health
    interval: 30s
    rules:
      # Agente caÃ­do
      - alert: AgentDown
        expr: up{job="customer-agents"} == 0
        for: 2m
        labels:
          severity: critical
        annotations:
          summary: "Agente {{ $labels.node_id }} caÃ­do"
      
      # No puede conectar al Collector
      - alert: AgentCollectorUnreachable
        expr: agent_collector_reachable == 0
        for: 5m
        labels:
          severity: warning
        annotations:
          summary: "Agente {{ $labels.node_id }} no alcanza Collector"
      
      # Buffer saturado
      - alert: AgentBufferSaturated
        expr: agent_buffer_usage_percent > 80
        for: 5m
        labels:
          severity: warning
        annotations:
          summary: "Buffer del agente {{ $labels.node_id }} al {{ $value }}%"
      
      # Alto uso de memoria
      - alert: AgentHighMemory
        expr: agent_memory_usage_mb > 200
        for: 10m
        labels:
          severity: warning
        annotations:
          summary: "Agente {{ $labels.node_id }} usando {{ $value }}MB RAM"
```

### Dashboard en Grafana

Paneles recomendados:
1. **Estado de Agentes**: Mapa de todos los agentes (verde/rojo)
2. **Conectividad**: GrÃ¡fica de agentes conectados al Collector
3. **Buffer Usage**: Uso del buffer por agente
4. **System Metrics**: CPU, RAM, Disco por nodo
5. **Throughput**: Spans enviados por segundo

---

## ðŸ§ª Testing

### Test Local

```bash
# 1. Levantar un collector local
cd services/collector
docker-compose up -d

# 2. Configurar agente para apuntar local
export OTEL_EXPORTER_OTLP_ENDPOINT=http://localhost:4317

# 3. Ejecutar agente
go run main.go

# 4. Verificar que envÃ­a datos
docker logs otel-collector | grep "Span"
```

### Test de Carga

```bash
# Simular 1000 spans/segundo
for i in {1..1000}; do
  curl -X POST http://localhost:4317/v1/traces &
done
wait

# Ver mÃ©tricas del agente
curl http://localhost:8080/metrics | grep agent_spans
```

---

## ðŸ“š Referencias

- [OpenTelemetry Go SDK](https://github.com/open-telemetry/opentelemetry-go)
- [OTLP Specification](https://github.com/open-telemetry/opentelemetry-proto)
- [Go SDK Examples](https://github.com/open-telemetry/opentelemetry-go/tree/main/example)
- [Best Practices](https://opentelemetry.io/docs/instrumentation/go/manual/)

---

## ðŸŽ¯ Checklist de Deployment

- [ ] Variables de entorno configuradas (`CUSTOMER_ID`, `NODE_ID`)
- [ ] Conectividad al Collector verificada (puerto 4317)
- [ ] Health check respondiendo (puerto 8080)
- [ ] Prometheus configurado para scrappear `/metrics`
- [ ] Alertas configuradas en Prometheus
- [ ] Dashboard en Grafana creado
- [ ] Logs siendo recolectados
- [ ] Recursos limitados en Docker/K8s
- [ ] Restart policy configurado
- [ ] Monitoreo del propio agente activo

---

**VersiÃ³n**: 1.0.0
**Ãšltima actualizaciÃ³n**: Octubre 31, 2025
