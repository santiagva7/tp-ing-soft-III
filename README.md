# Sistema de Monitoreo Multi-tenant con OpenTelemetry

## ğŸ“‹ VisiÃ³n General

Sistema de monitoreo de infraestructura como servicio (SaaS) que permite a mÃºltiples clientes tercerizar la administraciÃ³n y observabilidad de sus nodos mediante OpenTelemetry, con almacenamiento hÃ­brido (Prometheus + Cassandra) y visualizaciÃ³n centralizada en Grafana.

### Propuesta de Valor

Ofrecer a empresas una **soluciÃ³n completa de observabilidad** sin la complejidad de mantener su propia infraestructura de monitoreo:
- âœ… **InstalaciÃ³n simple**: Un agente ligero en Go por nodo
- âœ… **Visibilidad en tiempo real**: CPU, RAM, latencia, trazas distribuidas
- âœ… **Alertas proactivas**: DetecciÃ³n automÃ¡tica de problemas
- âœ… **Dashboard multi-tenant**: Cada cliente ve solo sus nodos
- âœ… **RetenciÃ³n histÃ³rica**: 30 dÃ­as hot + 2 aÃ±os cold storage
- âœ… **SLA garantizado**: Tracking automÃ¡tico de uptime

---

## ğŸ—ï¸ Arquitectura del Sistema

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    INFRAESTRUCTURA DE CLIENTES                       â”‚
â”‚                     (Nodos Remotos - Miles)                          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                      â”‚
â”‚  Cliente A - Nodo 1          Cliente A - Nodo 2    Cliente B ...    â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                â”‚
â”‚  â”‚  Agente Go + SDK    â”‚    â”‚  Agente Go + SDK    â”‚                â”‚
â”‚  â”‚  OpenTelemetry      â”‚    â”‚  OpenTelemetry      â”‚                â”‚
â”‚  â”‚                     â”‚    â”‚                     â”‚                â”‚
â”‚  â”‚  ğŸ“Š Genera:         â”‚    â”‚  ğŸ“Š Genera:         â”‚                â”‚
â”‚  â”‚  - MÃ©tricas (CPU,   â”‚    â”‚  - MÃ©tricas         â”‚                â”‚
â”‚  â”‚    RAM, disco)      â”‚    â”‚  - Trazas           â”‚                â”‚
â”‚  â”‚  - Trazas           â”‚    â”‚  - Logs             â”‚                â”‚
â”‚  â”‚  - Logs             â”‚    â”‚                     â”‚                â”‚
â”‚  â”‚                     â”‚    â”‚                     â”‚                â”‚
â”‚  â”‚  ğŸ¥ Expone:         â”‚    â”‚  ğŸ¥ Expone:         â”‚                â”‚
â”‚  â”‚  GET /health        â”‚    â”‚  GET /health        â”‚                â”‚
â”‚  â”‚  (estado del nodo)  â”‚    â”‚  (estado del nodo)  â”‚                â”‚
â”‚  â”‚                     â”‚    â”‚                     â”‚                â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                â”‚
â”‚             â”‚                           â”‚                           â”‚
â”‚             â”‚ OTLP (gRPC)              â”‚ OTLP (gRPC)               â”‚
â”‚             â”‚ TelemetrÃ­a tiempo real   â”‚ TelemetrÃ­a tiempo real    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
              â”‚                           â”‚
              â”‚      Internet / VPN       â”‚
              â”‚                           â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚             â”‚  TU INFRAESTRUCTURA CENTRAL (Proveedor SaaS)          â”‚
â”‚             â”‚                           â”‚                           â”‚
â”‚             â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                           â”‚
â”‚                         â”‚                                            â”‚
â”‚                â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”                                   â”‚
â”‚                â”‚  Collector      â”‚                                   â”‚
â”‚                â”‚  OpenTelemetry  â”‚                                   â”‚
â”‚                â”‚  (Dispatcher)   â”‚                                   â”‚
â”‚                â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜                                   â”‚
â”‚                         â”‚                                            â”‚
â”‚            â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                               â”‚
â”‚            â”‚                         â”‚                               â”‚
â”‚    â”Œâ”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”        â”Œâ”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                  â”‚
â”‚    â”‚   HOT PATH     â”‚        â”‚   COLD PATH      â”‚                  â”‚
â”‚    â”‚   Prometheus   â”‚        â”‚   Cassandra      â”‚                  â”‚
â”‚    â”‚                â”‚        â”‚   Cluster        â”‚                  â”‚
â”‚    â”‚  - 30 dÃ­as     â”‚        â”‚                  â”‚                  â”‚
â”‚    â”‚  - Queries     â”‚        â”‚  - 1-2 aÃ±os      â”‚                  â”‚
â”‚    â”‚    rÃ¡pidas     â”‚        â”‚  - Queries       â”‚                  â”‚
â”‚    â”‚    (50-200ms)  â”‚        â”‚    lentas        â”‚                  â”‚
â”‚    â”‚  - In-memory   â”‚        â”‚    (500-2000ms)  â”‚                  â”‚
â”‚    â””â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜        â”‚  - Distributed   â”‚                  â”‚
â”‚            â”‚                 â”‚  - 3+ nodos      â”‚                  â”‚
â”‚            â”‚                 â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                  â”‚
â”‚            â”‚                        â”‚                               â”‚
â”‚            â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                               â”‚
â”‚                         â”‚                                            â”‚
â”‚                â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”                                   â”‚
â”‚                â”‚    Grafana      â”‚                                   â”‚
â”‚                â”‚  (Multi-tenant) â”‚                                   â”‚
â”‚                â”‚                 â”‚                                   â”‚
â”‚                â”‚  Query Router:  â”‚                                   â”‚
â”‚                â”‚  < 30d â†’ Prom   â”‚                                   â”‚
â”‚                â”‚  > 30d â†’ Cass   â”‚                                   â”‚
â”‚                â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                                   â”‚
â”‚                         â”‚                                            â”‚
â”‚                         â–¼                                            â”‚
â”‚            â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                                â”‚
â”‚            â”‚  Tu Dashboard SaaS     â”‚                                â”‚
â”‚            â”‚  - Lista de clientes   â”‚                                â”‚
â”‚            â”‚  - Estado de nodos ğŸŸ¢ğŸ”´â”‚                                â”‚
â”‚            â”‚  - MÃ©tricas en vivo    â”‚                                â”‚
â”‚            â”‚  - Alertas             â”‚                                â”‚
â”‚            â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                                â”‚
â”‚                         â–²                                            â”‚
â”‚                         â”‚                                            â”‚
â”‚                â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”                                   â”‚
â”‚                â”‚   Prometheus    â”‚                                   â”‚
â”‚                â”‚   (Scraper)     â”‚                                   â”‚
â”‚                â”‚                 â”‚                                   â”‚
â”‚                â”‚  Scrappea /health de cada agente                    â”‚
â”‚                â”‚  cada 30s para detectar nodos caÃ­dos                â”‚
â”‚                â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                                   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ”„ Flujos de Datos

### 1. **TelemetrÃ­a en Tiempo Real (gRPC/OTLP)**

```
PropÃ³sito: MÃ©tricas de negocio y rendimiento del nodo

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Agente (Nodo)  â”‚
â”‚                 â”‚
â”‚  SDK genera:    â”‚
â”‚  - CPU: 75%     â”‚
â”‚  - RAM: 8.5GB   â”‚
â”‚  - Disco: 80%   â”‚
â”‚  - Latencia: 45msâ”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â”‚ OTLP (gRPC - Puerto 4317)
         â”‚ Push continuo
         â”‚ Alta frecuencia (cada 15s)
         â”‚ Payload: Kilobytes/segundo
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Collector     â”‚
â”‚   (Procesa)     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
         â”‚                    â”‚
         â–¼                    â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Prometheus  â”‚      â”‚  Cassandra    â”‚
â”‚ (Hot - 30d) â”‚      â”‚  (Cold - 2y)  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚                    â”‚
         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                   â”‚
                   â–¼
           â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
           â”‚   Grafana    â”‚
           â”‚  Dashboards  â”‚
           â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**CaracterÃ­sticas:**
- **DirecciÃ³n**: Agente â†’ Collector (push model)
- **Protocolo**: gRPC (OTLP)
- **Frecuencia**: Continua (cada 15 segundos)
- **Contenido**: MÃ©tricas, trazas, logs de la aplicaciÃ³n
- **Persistencia**: Prometheus (30d) + Cassandra (2 aÃ±os)

---

### 2. **Health Checks (HTTP)**

```
PropÃ³sito: Estado del agente y conectividad

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Prometheus     â”‚
â”‚  (Scraper)      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â”‚ HTTP GET /health (Puerto 8080)
         â”‚ Pull cada 30s
         â”‚ Payload: ~1 KB
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Agente (Nodo)  â”‚
â”‚                 â”‚
â”‚  Responde:      â”‚
â”‚  {              â”‚
â”‚   "status": "healthy",â”‚
â”‚   "collector_reachable": true,â”‚
â”‚   "buffer_usage": "25%",â”‚
â”‚   "uptime": "72h"â”‚
â”‚  }              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**CaracterÃ­sticas:**
- **DirecciÃ³n**: Prometheus â†’ Agente (pull model)
- **Protocolo**: HTTP/JSON
- **Frecuencia**: Cada 30 segundos
- **Contenido**: Estado del agente, conectividad, uso de buffer
- **Persistencia**: Prometheus (30d)
- **Uso**: Alertas, dashboard de estado, SLA tracking

---

## ğŸ“ Estructura del Proyecto

```
tp-ing-soft-III/
â”œâ”€â”€ README.md                          # Este archivo
â”œâ”€â”€ services/
â”‚   â”œâ”€â”€ agent/                         # Agente que va en nodos de clientes
â”‚   â”‚   â”œâ”€â”€ README.md                  # DocumentaciÃ³n del agente
â”‚   â”‚   â”œâ”€â”€ docker-compose.yaml        # Deployment del agente
â”‚   â”‚   â”œâ”€â”€ otel-agent-config.yaml     # ConfiguraciÃ³n OpenTelemetry
â”‚   â”‚   â””â”€â”€ main.go                    # (Futuro) CÃ³digo del agente
â”‚   â”‚
â”‚   â”œâ”€â”€ collector/                     # Collector central (tu infra)
â”‚   â”‚   â”œâ”€â”€ README.md                  # DocumentaciÃ³n del collector
â”‚   â”‚   â”œâ”€â”€ docker-compose.yaml        # Deployment del collector
â”‚   â”‚   â”œâ”€â”€ otel-collector-config.yaml # ConfiguraciÃ³n del collector
â”‚   â”‚   â”œâ”€â”€ example.py                 # Cliente ejemplo que envÃ­a datos
â”‚   â”‚   â”œâ”€â”€ test_collector.py          # Tests del collector
â”‚   â”‚   â””â”€â”€ requirements.txt           # Dependencias Python
â”‚   â”‚
â”‚   â”œâ”€â”€ storage/                       # Capa de almacenamiento hÃ­brido
â”‚   â”‚   â”œâ”€â”€ README.md                  # DocumentaciÃ³n del storage
â”‚   â”‚   â”œâ”€â”€ docker-compose.yaml        # (Futuro) Prometheus + Cassandra
â”‚   â”‚   â”œâ”€â”€ prometheus/
â”‚   â”‚   â”‚   â””â”€â”€ prometheus.yml         # (Futuro) Config Prometheus
â”‚   â”‚   â”œâ”€â”€ cassandra/
â”‚   â”‚   â”‚   â””â”€â”€ schema.cql             # (Futuro) Esquema de tablas
â”‚   â”‚   â””â”€â”€ grafana/
â”‚   â”‚       â””â”€â”€ dashboards/            # (Futuro) Dashboards preconfigured
â”‚   â”‚
â”‚   â””â”€â”€ monitor/                       # Dashboard de observabilidad
â”‚       â”œâ”€â”€ README.md                  # DocumentaciÃ³n del dashboard
â”‚       â”œâ”€â”€ docker-compose.yaml        # (Futuro) Grafana + configs
â”‚       â”œâ”€â”€ grafana/
â”‚       â”‚   â”œâ”€â”€ dashboards/            # (Futuro) Dashboards JSON
â”‚       â”‚   â”œâ”€â”€ datasources/           # (Futuro) Datasources config
â”‚       â”‚   â””â”€â”€ alerting/              # (Futuro) Alerting rules
â”‚       â””â”€â”€ prometheus/
â”‚           â”œâ”€â”€ prometheus.yml         # (Futuro) Prometheus config
â”‚           â””â”€â”€ alerts/                # (Futuro) Alert rules
â”‚
â””â”€â”€ docs/                              # (Futuro) DocumentaciÃ³n adicional
    â”œâ”€â”€ architecture.md
    â”œâ”€â”€ deployment.md
    â””â”€â”€ api.md
```

---

## ğŸ¯ Componentes Clave

### 1. **Agente (Go + OpenTelemetry SDK)**

**UbicaciÃ³n**: `services/agent/`

**DescripciÃ³n**: AplicaciÃ³n ligera en Go que se despliega en cada nodo del cliente.

**Responsabilidades**:
- âœ… Generar telemetrÃ­a mediante SDK de OpenTelemetry
- âœ… Instrumentar aplicaciones del cliente automÃ¡ticamente
- âœ… Exportar datos vÃ­a OTLP al Collector central
- âœ… Exponer endpoint `/health` para monitoreo de estado
- âœ… Etiquetar datos con `customer_id`, `node_id`, `environment`
- âœ… Bufferear datos en memoria ante fallos del Collector

**CaracterÃ­sticas tÃ©cnicas**:
- Lenguaje: Go
- SDK: `go.opentelemetry.io/otel`
- Protocolos: gRPC (OTLP), HTTP (health checks)
- Puertos: 4317 (OTLP gRPC saliente), 8080 (HTTP /health entrante)
- Recursos: ~50-100 MB RAM, mÃ­nimo overhead CPU

**Ver**: [services/agent/README.md](services/agent/README.md)

---

### 2. **Collector (OpenTelemetry Collector)**

**UbicaciÃ³n**: `services/collector/`

**DescripciÃ³n**: Componente central que recibe telemetrÃ­a de todos los agentes y la distribuye a los sistemas de almacenamiento.

**Responsabilidades**:
- âœ… Recibir datos OTLP de mÃºltiples agentes
- âœ… Procesar y enriquecer datos (batching, filtering)
- âœ… Validar multi-tenancy (cada span tiene `customer_id`)
- âœ… Exportar a Prometheus (hot path)
- âœ… Exportar a Cassandra (cold path)
- âœ… Exponer mÃ©tricas propias y health checks

**CaracterÃ­sticas tÃ©cnicas**:
- Imagen: `otel/opentelemetry-collector-contrib`
- Receivers: OTLP (gRPC, HTTP)
- Processors: batch, attributes, filter, memory_limiter
- Exporters: prometheus, otlphttp/cassandra
- Puertos: 4317 (gRPC), 4318 (HTTP), 8889 (Prometheus metrics), 13133 (health)

**Ver**: [services/collector/README.md](services/collector/README.md)

---

### 3. **Storage Layer (Prometheus + Cassandra)**

**UbicaciÃ³n**: `services/storage/`

**DescripciÃ³n**: Arquitectura hÃ­brida de almacenamiento que combina hot storage (Prometheus) para queries rÃ¡pidas y cold storage (Cassandra) para retenciÃ³n a largo plazo.

#### 3.1 **Prometheus (Hot Storage)**

**PropÃ³sito**: Datos recientes para dashboards en tiempo real

**CaracterÃ­sticas**:
- âš¡ Latencia ultra-baja: 50-200ms
- ğŸ“Š RetenciÃ³n: 30 dÃ­as
- ğŸ¯ Optimizado para series temporales
- ğŸ”” Alerting integrado (Alertmanager)
- ğŸ“ˆ PromQL para queries complejas

**Casos de uso**:
- Dashboards en tiempo real
- Alertas crÃ­ticas (< 5 minutos)
- Troubleshooting activo
- AnÃ¡lisis de Ãºltimas 24-72 horas

#### 3.2 **Cassandra (Cold Storage)**

**PropÃ³sito**: Datos histÃ³ricos para anÃ¡lisis y compliance

**CaracterÃ­sticas**:
- ğŸ’¾ RetenciÃ³n masiva: 1-2 aÃ±os
- ğŸŒ Distribuido: 3+ nodos con replicaciÃ³n
- ğŸ“ˆ Escalabilidad horizontal
- ğŸ”’ Durabilidad: Sin pÃ©rdida de datos
- âš¡ Write-optimized: Alto throughput

**Casos de uso**:
- AnÃ¡lisis histÃ³rico (> 30 dÃ­as)
- Reportes mensuales/anuales
- Compliance y auditorÃ­a
- Capacity planning
- Forensics post-mortem

#### 3.3 **Query Router**

LÃ³gica en Grafana que enruta queries automÃ¡ticamente:
- **< 30 dÃ­as**: Query a Prometheus (rÃ¡pido)
- **> 30 dÃ­as**: Query a Cassandra (lento pero tiene datos)

**Ver**: [services/storage/README.md](services/storage/README.md)

---

### 4. **Grafana (VisualizaciÃ³n Multi-tenant)**

**UbicaciÃ³n**: `services/monitor/`

**DescripciÃ³n**: Dashboard centralizado con separaciÃ³n por cliente.

**CaracterÃ­sticas**:
- ğŸ“Š Dashboards predefinidos por tipo de nodo
- ğŸ” Multi-tenancy: Cada cliente ve solo sus nodos
- ğŸ¨ Visualizaciones en tiempo real
- ğŸ”” IntegraciÃ³n con Alertmanager
- ğŸ“ˆ Query routing automÃ¡tico (Prometheus vs Cassandra)

**Paneles principales**:
1. **Vista Global**: Lista de todos los clientes y estado de nodos
2. **Vista por Cliente**: MÃ©tricas detalladas de todos sus nodos
3. **Vista por Nodo**: Drill-down de un nodo especÃ­fico
4. **Alertas**: Dashboard de alertas activas
5. **Infraestructura (SRE)**: Vista tÃ©cnica del sistema completo

**Ver**: [services/monitor/README.md](services/monitor/README.md)

---

## ğŸ”€ Escenarios de OperaciÃ³n

### âœ… OperaciÃ³n Normal

```
1. Agente genera mÃ©tricas
   â””â”€ CPU: 45%, RAM: 8GB, Latencia: 25ms

2. Agente envÃ­a vÃ­a OTLP al Collector
   â””â”€ gRPC: collector.tuempresa.com:4317

3. Collector recibe y despacha
   â”œâ”€ Prometheus: Escribe mÃ©tricas (hot)
   â””â”€ Cassandra: Escribe mÃ©tricas (cold)

4. Prometheus scrappea /health del agente
   â””â”€ Respuesta: 200 OK {"status": "healthy"}

5. Usuario consulta Grafana
   â”œâ”€ Rango: Ãºltimas 24h â†’ Query a Prometheus (150ms)
   â””â”€ Muestra grÃ¡fica en tiempo real
```

---

### âš ï¸ Escenario: Collector CaÃ­do

```
1. Agente intenta enviar OTLP
   â””â”€ Error: connection refused

2. SDK de Go maneja el fallo
   â”œâ”€ Reintenta con backoff exponencial
   â”œâ”€ Buffer se llena gradualmente
   â””â”€ Status: "degraded" (funciona pero sin enviar)

3. Prometheus scrappea /health
   â””â”€ Respuesta: 200 OK {
       "status": "degraded",
       "collector_reachable": false,
       "buffer_usage": "75%"
     }

4. Alerta automÃ¡tica activada
   â”œâ”€ Severity: warning
   â””â”€ Mensaje: "Agente no puede alcanzar Collector"

5. TÃš recibes alerta y reinicia Collector

6. Collector vuelve online

7. Agente reconecta y vacÃ­a buffer
   â””â”€ Status: "healthy"
```

---

### ğŸ”´ Escenario: Nodo del Cliente CaÃ­do

```
1. Nodo del cliente se apaga (ej: mantenimiento)

2. Prometheus intenta scrappear /health
   â””â”€ Error: timeout (no responde)

3. DespuÃ©s de 3 intentos fallidos (2 minutos)
   â””â”€ Prometheus marca: up{node="cliente-a-nodo-1"} = 0

4. Alerta activada
   â”œâ”€ Severity: critical
   â””â”€ Mensaje: "Nodo cliente-a-nodo-1 estÃ¡ caÃ­do"

5. Notificaciones enviadas
   â”œâ”€ Email al cliente
   â”œâ”€ Slack channel
   â””â”€ Dashboard muestra: ğŸ”´ cliente-a-nodo-1: DOWN

6. Cliente ve alerta y reinicia nodo

7. Nodo vuelve online

8. Prometheus scrappea /health exitosamente
   â””â”€ up{node="cliente-a-nodo-1"} = 1

9. Dashboard actualiza: ğŸŸ¢ cliente-a-nodo-1: HEALTHY
```

---

## ğŸ“Š Flujo de Datos Multi-tenant

### Etiquetado de Datos

Todos los datos llevan labels de identificaciÃ³n:

```go
// En el agente
resource := resource.NewWithAttributes(
    semconv.SchemaURL,
    semconv.ServiceNameKey.String("customer-app"),
    attribute.String("customer.id", "cliente-a"),
    attribute.String("customer.name", "Empresa XYZ"),
    attribute.String("node.id", "prod-web-01"),
    attribute.String("node.region", "us-east-1"),
    attribute.String("environment", "production"),
)
```

### Query en Grafana

```promql
# CPU de todos los nodos de cliente-a
avg(system_cpu_usage{customer_id="cliente-a"}) by (node_id)

# Nodos caÃ­dos de cliente-b
up{customer_id="cliente-b"} == 0

# Latencia promedio por cliente
avg(http_request_duration_seconds{customer_id="$customer"})
```

### Aislamiento de Datos

- **Grafana**: Variables de dashboard filtran por `customer_id`
- **Collector**: Procesador `filter` valida presencia de `customer_id`
- **Cassandra**: Partitioning key incluye `customer_id`
- **Prometheus**: Labels permiten queries segregadas

---

## ğŸš€ Quick Start

### Prerrequisitos

- Docker & Docker Compose
- Go 1.21+ (para desarrollar el agente)
- Acceso a red entre nodos de clientes y tu infraestructura

### Deployment MÃ­nimo

#### 1. Levantar Collector Central

```bash
cd services/collector
docker-compose up -d
```

Verifica que estÃ© corriendo:
```bash
curl http://localhost:13133/health
# Debe responder: 200 OK
```

#### 2. Desplegar Agente en Nodo del Cliente

```bash
cd services/agent
# Editar docker-compose.yaml con la IP/dominio de tu Collector
docker-compose up -d
```

Verifica que estÃ© corriendo:
```bash
curl http://localhost:8080/health
# Debe responder: {"status": "healthy", ...}
```

#### 3. Levantar Storage Layer

```bash
cd services/storage
docker-compose up -d
```

Verifica Prometheus:
```bash
curl http://localhost:9090/-/healthy
```

Verifica Cassandra:
```bash
docker exec -it cassandra-cold-1 nodetool status
```

#### 4. Acceder a Grafana

```
URL: http://localhost:3000
User: admin
Pass: admin
```

Importa dashboards desde `services/storage/grafana/dashboards/`

---

## ğŸ“ˆ Monitoreo del Sistema

### MÃ©tricas del Collector

```promql
# Tasa de ingesta de spans
rate(otelcol_receiver_accepted_spans[5m])

# Latencia del collector
histogram_quantile(0.95, otelcol_processor_batch_batch_send_duration_bucket)

# Errores de exportaciÃ³n
rate(otelcol_exporter_send_failed_spans[5m])
```

### MÃ©tricas de los Agentes

```promql
# Nodos activos por cliente
count(up{job="customer-agents"} == 1) by (customer_id)

# Uso de CPU promedio
avg(system_cpu_usage) by (customer_id, node_id)

# Agentes con buffer saturado
agent_buffer_usage_percent > 80
```

### Health Checks

```promql
# Nodos DOWN
up{job="customer-agents"} == 0

# Agentes con problemas de conectividad
agent_collector_reachable == 0
```

---

## ğŸ”” Alertas Recomendadas

### Alertas CrÃ­ticas

```yaml
groups:
  - name: critical_alerts
    interval: 30s
    rules:
      # Nodo caÃ­do
      - alert: CustomerNodeDown
        expr: up{job="customer-agents"} == 0
        for: 2m
        labels:
          severity: critical
        annotations:
          summary: "Nodo {{ $labels.node_id }} del cliente {{ $labels.customer_id }} estÃ¡ caÃ­do"
      
      # Collector caÃ­do
      - alert: CollectorDown
        expr: up{job="otel-collector"} == 0
        for: 1m
        labels:
          severity: critical
        annotations:
          summary: "Collector central estÃ¡ caÃ­do - sin ingesta de datos"
      
      # Buffer del agente saturado
      - alert: AgentBufferSaturated
        expr: agent_buffer_usage_percent > 90
        for: 5m
        labels:
          severity: critical
        annotations:
          summary: "Buffer del agente {{ $labels.node_id }} al {{ $value }}%"
```

### Alertas de Warning

```yaml
      # Agente no puede alcanzar Collector
      - alert: AgentCollectorUnreachable
        expr: agent_collector_reachable == 0
        for: 5m
        labels:
          severity: warning
        annotations:
          summary: "Agente {{ $labels.node_id }} no puede conectar al Collector"
      
      # CPU alta en nodo
      - alert: HighCPUUsage
        expr: system_cpu_usage > 85
        for: 10m
        labels:
          severity: warning
        annotations:
          summary: "CPU alta en {{ $labels.node_id }}: {{ $value }}%"
      
      # Memoria alta
      - alert: HighMemoryUsage
        expr: system_memory_usage_percent > 90
        for: 10m
        labels:
          severity: warning
        annotations:
          summary: "Memoria alta en {{ $labels.node_id }}: {{ $value }}%"
```

---

## ğŸ”’ Seguridad y Multi-tenancy

### Aislamiento de Datos

1. **Nivel de Agente**: Cada agente etiqueta datos con `customer_id`
2. **Nivel de Collector**: Filtro rechaza datos sin `customer_id`
3. **Nivel de Storage**: Cassandra usa `customer_id` como partition key
4. **Nivel de VisualizaciÃ³n**: Grafana filtra por organizaciÃ³n/usuario

### AutenticaciÃ³n y AutorizaciÃ³n

```yaml
# En el Collector (futuro)
extensions:
  bearertoken:
    scheme: "Bearer"
    token: "${CUSTOMER_API_TOKEN}"

receivers:
  otlp:
    protocols:
      grpc:
        auth:
          authenticator: bearertoken
```

### EncriptaciÃ³n

- **En trÃ¡nsito**: TLS para OTLP y health checks
- **En reposo**: EncriptaciÃ³n de volÃºmenes Cassandra
- **Secrets**: Variables de entorno, no hardcoded

---

## ğŸ“Š Capacidad y Escalamiento

### Dimensionamiento

#### Para 100 clientes con 500 nodos totales:

**Agentes** (por nodo):
- CPU: ~0.1 core
- RAM: ~50-100 MB
- Network: ~10 KB/s saliente

**Collector** (centralizado):
- CPU: 8-16 cores
- RAM: 16-32 GB
- Network: 5-10 MB/s entrante
- Escalamiento: Horizontal (mÃºltiples collectors con load balancer)

**Prometheus** (hot storage):
- CPU: 4-8 cores
- RAM: 16-32 GB
- Disco: 500 GB - 1 TB SSD
- Escalamiento: Vertical + Thanos para HA

**Cassandra** (cold storage):
- CPU: 8-16 cores por nodo
- RAM: 32-64 GB por nodo
- Disco: 1-4 TB SSD por nodo
- Nodos: MÃ­nimo 3, escala horizontalmente

**Grafana**:
- CPU: 2-4 cores
- RAM: 4-8 GB
- Escalamiento: MÃºltiples instancias con shared database

### ProyecciÃ³n de Crecimiento

| Clientes | Nodos | MÃ©tricas/s | Collectors | Cassandra Nodes | Costo Mensual (AWS) |
|----------|-------|------------|------------|-----------------|---------------------|
| 10       | 50    | 5,000      | 1          | 3               | ~$1,500             |
| 50       | 250   | 25,000     | 2          | 3               | ~$3,500             |
| 100      | 500   | 50,000     | 3          | 5               | ~$7,000             |
| 500      | 2,500 | 250,000    | 10         | 9               | ~$25,000            |
| 1,000    | 5,000 | 500,000    | 20         | 15              | ~$50,000            |

---

## ğŸ› ï¸ Desarrollo

### Estructura de Branches

```
main          â†’ ProducciÃ³n estable
develop       â†’ IntegraciÃ³n continua
feature/*     â†’ Nuevas funcionalidades
bugfix/*      â†’ CorrecciÃ³n de bugs
hotfix/*      â†’ Fixes urgentes en producciÃ³n
```

### Testing

```bash
# Tests del Collector
cd services/collector
python -m pytest test_collector.py

# Tests del Agente (futuro)
cd services/agent
go test ./...

# Tests de integraciÃ³n (futuro)
cd tests/integration
./run_integration_tests.sh
```

### Contribuir

1. Fork el repositorio
2. Crea una rama: `git checkout -b feature/nueva-funcionalidad`
3. Commit cambios: `git commit -am 'Agrega nueva funcionalidad'`
4. Push: `git push origin feature/nueva-funcionalidad`
5. Abre un Pull Request

---

## ğŸ“š DocumentaciÃ³n Adicional

- **[Agent README](services/agent/README.md)**: Detalles del agente Go con SDK OpenTelemetry
- **[Collector README](services/collector/README.md)**: ConfiguraciÃ³n del collector central
- **[Storage README](services/storage/README.md)**: Arquitectura hÃ­brida de almacenamiento (Prometheus + Cassandra)
- **[Monitor README](services/monitor/README.md)**: Dashboard de observabilidad multi-tenant con Grafana
- **[OpenTelemetry Docs](https://opentelemetry.io/docs/)**: DocumentaciÃ³n oficial
- **[Prometheus Docs](https://prometheus.io/docs/)**: DocumentaciÃ³n de Prometheus
- **[Cassandra Docs](https://cassandra.apache.org/doc/)**: DocumentaciÃ³n de Cassandra
- **[Grafana Docs](https://grafana.com/docs/)**: DocumentaciÃ³n de Grafana

---

## ğŸ¯ Roadmap

### Fase 1: MVP (Actual)
- [x] Arquitectura base definida
- [x] DocumentaciÃ³n completa
- [ ] Collector funcional
- [ ] Agente bÃ¡sico en Go
- [ ] Prometheus configurado
- [ ] Dashboard bÃ¡sico en Grafana

### Fase 2: Funcionalidad Core (Q1 2026)
- [ ] Cassandra cluster operacional
- [ ] Query routing automÃ¡tico
- [ ] Sistema de alertas completo
- [ ] AutenticaciÃ³n multi-tenant
- [ ] API REST para gestiÃ³n de clientes

### Fase 3: Enterprise Features (Q2 2026)
- [ ] Downsampling automÃ¡tico
- [ ] Backup y disaster recovery
- [ ] SLA tracking y reporting
- [ ] FacturaciÃ³n automÃ¡tica
- [ ] Portal de clientes (self-service)

### Fase 4: Advanced (Q3 2026)
- [ ] Machine Learning para anomaly detection
- [ ] Auto-scaling de Collector y Cassandra
- [ ] Multi-regiÃ³n geogrÃ¡fica
- [ ] Compliance certifications (SOC2, ISO27001)

---

## ğŸ¤ Equipo

- **Repository Owner**: [santiagva7](https://github.com/santiagva7)
- **Contributors**: Ver [Contributors](../../graphs/contributors)

---

## ğŸ“„ Licencia

Este proyecto es privado y propiedad del equipo de desarrollo.

---

## ğŸ’¡ Conceptos Clave

### Â¿Por quÃ© OpenTelemetry?

- **Vendor-neutral**: No lock-in con un proveedor especÃ­fico
- **EstÃ¡ndar de industria**: Adoptado por CNCF
- **Observabilidad unificada**: Trazas + MÃ©tricas + Logs en un solo SDK
- **Ecosistema rico**: IntegraciÃ³n con 100+ tecnologÃ­as
- **InstrumentaciÃ³n automÃ¡tica**: Muchos frameworks ya soportados

### Â¿Por quÃ© Arquitectura HÃ­brida (Prometheus + Cassandra)?

- **Best of both worlds**:
  - Prometheus: Queries ultra-rÃ¡pidas para tiempo real
  - Cassandra: RetenciÃ³n masiva para histÃ³rico
- **OptimizaciÃ³n de costos**: No pagar por SSD rÃ¡pido para datos viejos
- **Compliance**: RetenciÃ³n de 2 aÃ±os sin romper el banco
- **Escalabilidad**: Prometheus vertical, Cassandra horizontal

### Â¿Por quÃ© Doble Flujo (OTLP + /health)?

- **OTLP (gRPC)**: TelemetrÃ­a de negocio (CPU, RAM, latencia)
  - Push model: Agente envÃ­a continuamente
  - Alto volumen de datos
  
- **/health (HTTP)**: Estado del agente mismo
  - Pull model: Prometheus scrappea
  - Bajo volumen, alta confiabilidad
  - Independiente del Collector (detecta problemas de red)

---

## ğŸ” Troubleshooting

### Agente no puede conectar al Collector

```bash
# Verificar conectividad de red
curl -v telnet://collector.tuempresa.com:4317

# Check logs del agente
docker logs otel-agent

# Verificar firewall/security groups
# Debe permitir: puerto 4317 (gRPC) y 8080 (HTTP)
```

### Collector no recibe datos

```bash
# Check logs del Collector
docker logs otel-collector

# Verificar health
curl http://localhost:13133/health

# Ver mÃ©tricas internas
curl http://localhost:8888/metrics | grep otelcol_receiver
```

### Prometheus no scrappea agentes

```bash
# Ver targets en Prometheus
# http://localhost:9090/targets

# Verificar configuraciÃ³n
docker exec prometheus cat /etc/prometheus/prometheus.yml

# Test manual de health endpoint
curl http://<ip-agente>:8080/health
```

### Cassandra nodo caÃ­do

```bash
# Estado del cluster
docker exec cassandra-1 nodetool status

# Reiniciar nodo
docker restart cassandra-2

# Reparar datos despuÃ©s de caÃ­da
docker exec cassandra-2 nodetool repair -pr observability
```

---

## ğŸ“ Soporte

Para reportar issues o hacer preguntas:
- **Issues**: [GitHub Issues](../../issues)
- **Discussions**: [GitHub Discussions](../../discussions)
- **Email**: soporte@tuempresa.com (cuando estÃ© operativo)

---

**Ãšltima actualizaciÃ³n**: Octubre 31, 2025
**VersiÃ³n**: 1.0.0-MVP

